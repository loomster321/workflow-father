<!-- Generated by SpecStory -->

# Update Expected Duration Calculation (2025-04-07 10:57:27)

_**User**_

I want to change a couple of things. The expected_duration needs to be calculated based on the narration text word count.

Add an output field called word_count, and expected_duration should be calculated as word_count divided by 2.5.

---

_**Assistant**_

I'll modify the Scene Segmentation Agent System Instructions to include the word_count field and update the expected_duration calculation as requested.

---

```diff
  
  ### Output Format
- The output is a Scene Blueprint JSON array, where each object represents a scene with properties including scene_id, scene_narration (exact text from the input script), scene_description, suggested_visuals, suggested_audio (background_music and sound_effects), expected_duration (in seconds), and production_notes.
+ The output is a Scene Blueprint JSON array, where each object represents a scene with properties including scene_id, scene_narration (exact text from the input script), scene_description, suggested_visuals, suggested_audio (background_music and sound_effects), expected_duration (in seconds), word_count, and production_notes.
  
  ## Input Processing Guidelines
      },
      "expected_duration": 75,
+     "word_count": 150,
      "production_notes": "Creative production inputs and insights for the scene: goals, engagement strategy, emotional tone, contextual nuance"
    }
  ### Duration Calculation
  
- - Use industry-standard pacing (approximately 150 words per minute)
- - Factor in natural pauses and transitions
+ - Calculate word_count for each scene's narration text
+ - Calculate expected_duration as word_count divided by 2.5
  - Express duration in seconds (as a number, not a string)
- - Calculate based on word count and pacing considerations
+ - Ensure accurate word counting, excluding non-spoken markup if present
  
  ## Quality Verification
        "sound_effects": "Subtle digital processing sounds, soft UI interaction sounds"
      },
-     "expected_duration": 10,
+     "expected_duration": 75,
+     "word_count": 150,
      "production_notes": "Opening scene should establish an optimistic, educational tone; focus on creating visual excitement about the topic while maintaining accessibility"
    },
        "sound_effects": "Subtle hospital equipment sounds, soft beeping of monitors, gentle typing sounds"
      },
-     "expected_duration": 35,
+     "expected_duration": 75,
+     "word_count": 150,
      "production_notes": "Emphasize the human-AI collaboration rather than replacement; highlight the benefits to patients while maintaining emotional connection"
    },
        "sound_effects": "Subtle electric vehicle sounds, traffic ambience, technology interface sounds"
      },
-     "expected_duration": 30,
+     "expected_duration": 75,
+     "word_count": 150,
      "production_notes": "Visualize the sensing and decision-making capabilities of autonomous systems; emphasize safety and technological sophistication"
    },
        "sound_effects": "AI-generated musical notes, creative synthesis sounds, futuristic interface sounds"
      },
-     "expected_duration": 30,
+     "expected_duration": 75,
+     "word_count": 150,
      "production_notes": "Balance technological optimism with realistic representation; showcase creative applications that viewers might not have considered"
    },
        "sound_effects": "Subtle ambient sounds suggesting human activity and technology coexistence"
      },
-     "expected_duration": 35,
+     "expected_duration": 75,
+     "word_count": 150,
      "production_notes": "End on a thoughtful note that invites viewer consideration; emphasize human agency in shaping AI's future without being preachy"
    }
```

---

```diff
      },
      "expected_duration": 75,
-     "word_count": 150,
+     "word_count": 23,
      "production_notes": "Opening scene should establish an optimistic, educational tone; focus on creating visual excitement about the topic while maintaining accessibility"
    },
      },
      "expected_duration": 75,
-     "word_count": 150,
+     "word_count": 43,
      "production_notes": "Emphasize the human-AI collaboration rather than replacement; highlight the benefits to patients while maintaining emotional connection"
    },
      },
      "expected_duration": 75,
-     "word_count": 150,
+     "word_count": 39,
      "production_notes": "Visualize the sensing and decision-making capabilities of autonomous systems; emphasize safety and technological sophistication"
    },
      },
      "expected_duration": 75,
-     "word_count": 150,
+     "word_count": 35,
      "production_notes": "Balance technological optimism with realistic representation; showcase creative applications that viewers might not have considered"
    },
      },
      "expected_duration": 75,
-     "word_count": 150,
+     "word_count": 36,
      "production_notes": "End on a thoughtful note that invites viewer consideration; emphasize human agency in shaping AI's future without being preachy"
    }
```

---

```diff
        "sound_effects": "Subtle digital processing sounds, soft UI interaction sounds"
      },
-     "expected_duration": 75,
+     "expected_duration": 9,
      "word_count": 23,
      "production_notes": "Opening scene should establish an optimistic, educational tone; focus on creating visual excitement about the topic while maintaining accessibility"
        "sound_effects": "Subtle hospital equipment sounds, soft beeping of monitors, gentle typing sounds"
      },
-     "expected_duration": 75,
+     "expected_duration": 17,
      "word_count": 43,
      "production_notes": "Emphasize the human-AI collaboration rather than replacement; highlight the benefits to patients while maintaining emotional connection"
        "sound_effects": "Subtle electric vehicle sounds, traffic ambience, technology interface sounds"
      },
-     "expected_duration": 75,
+     "expected_duration": 16,
      "word_count": 39,
      "production_notes": "Visualize the sensing and decision-making capabilities of autonomous systems; emphasize safety and technological sophistication"
        "sound_effects": "AI-generated musical notes, creative synthesis sounds, futuristic interface sounds"
      },
-     "expected_duration": 75,
+     "expected_duration": 14,
      "word_count": 35,
      "production_notes": "Balance technological optimism with realistic representation; showcase creative applications that viewers might not have considered"
        "sound_effects": "Subtle ambient sounds suggesting human activity and technology coexistence"
      },
-     "expected_duration": 75,
+     "expected_duration": 14,
      "word_count": 36,
      "production_notes": "End on a thoughtful note that invites viewer consideration; emphasize human agency in shaping AI's future without being preachy"
```

---

```diff
        "sound_effects": "Recommended sound effects to enhance the scene"
      },
-     "expected_duration": 75,
-     "word_count": 150,
+     "expected_duration": 30,
+     "word_count": 75,
      "production_notes": "Creative production inputs and insights for the scene: goals, engagement strategy, emotional tone, contextual nuance"
    }
```

---

The Scene Segmentation Agent instructions have been updated with the following changes:

1. Added a new `word_count` field to the JSON output structure that counts the words in each scene's narration
2. Modified the duration calculation logic to use the formula: `expected_duration = word_count / 2.5`
3. Updated all examples to show accurate word counts for each scene and corresponding expected durations
4. Updated the Output Format description to include the new word_count field

These changes ensure that the Scene Segmentation Agent will now calculate more precise timing estimates based on the actual word count of each narration segment, with each second containing approximately 2.5 words as specified.

---

_**User**_

OK but your arithmatic in the example is all wrong. Would it be better if I put the calculations outside the agent inside an n8n javascript code node or can the agent handle the calculations without compromising the quality of the rest of its output?

---

_**Assistant**_

You're right about the arithmetic being incorrect in the examples. Let me assess the options:

1. **Agent handling calculations**: The Scene Segmentation agent can definitely handle simple calculations like dividing word count by 2.5. The errors in the examples were implementation mistakes, not capability limitations. When properly implemented, an LLM agent can reliably perform this calculation without compromising other outputs.

2. **External n8n JavaScript node**: This would provide absolute precision for calculations and might be preferred if:
   - You plan to implement more complex timing formulas later
   - You want to ensure the agent focuses purely on creative/analytical tasks
   - You prefer to keep business logic separate from content generation

For this simple calculation, either approach works well. If you're already using n8n and have a workflow set up, adding a JavaScript code node to handle the calculation would be clean and maintainable. The agent can output accurate word counts, and the n8n node can apply the formula consistently.

The best approach depends on your workflow architecture and where you want to locate this business logic.

---

_**User**_

OK I will split this into a seperate code node. Take all of the word count and duration fields out to the scene segmentation agent.

---

_**Assistant**_

```diff
  - Generate visual suggestions for each scene
  - Develop audio recommendations (background music, sound effects)
- - Calculate expected scene duration using industry-standard pacing
  - Structure output in a standardized JSON format
  - Ensure logical scene flow and appropriate segmentation
  
  ### Output Format
- The output is a Scene Blueprint JSON array, where each object represents a scene with properties including scene_id, scene_narration (exact text from the input script), scene_description, suggested_visuals, suggested_audio (background_music and sound_effects), expected_duration (in seconds), word_count, and production_notes.
+ The output is a Scene Blueprint JSON array, where each object represents a scene with properties including scene_id, scene_narration (exact text from the input script), scene_description, suggested_visuals, suggested_audio (background_music and sound_effects), and production_notes.
  
  ## Input Processing Guidelines
        "sound_effects": "Recommended sound effects to enhance the scene"
      },
-     "expected_duration": 30,
-     "word_count": 75,
      "production_notes": "Creative production inputs and insights for the scene: goals, engagement strategy, emotional tone, contextual nuance"
    }
  - Recommend sound effects that enhance the narrative
  - Consider pacing and emotional progression
- 
- ### Duration Calculation
- 
- - Calculate word_count for each scene's narration text
- - Calculate expected_duration as word_count divided by 2.5
- - Express duration in seconds (as a number, not a string)
- - Ensure accurate word counting, excluding non-spoken markup if present
  
  ## Quality Verification
  
  - Ensure logical scene flow and narrative continuity
- - Verify appropriate duration estimates
  - Check for unique and relevant visual/audio cues
  - Confirm proper JSON formatting and structure
        "sound_effects": "Subtle digital processing sounds, soft UI interaction sounds"
      },
-     "expected_duration": 9,
-     "word_count": 23,
      "production_notes": "Opening scene should establish an optimistic, educational tone; focus on creating visual excitement about the topic while maintaining accessibility"
    },
        "sound_effects": "Subtle hospital equipment sounds, soft beeping of monitors, gentle typing sounds"
      },
-     "expected_duration": 17,
-     "word_count": 43,
      "production_notes": "Emphasize the human-AI collaboration rather than replacement; highlight the benefits to patients while maintaining emotional connection"
    },
        "sound_effects": "Subtle electric vehicle sounds, traffic ambience, technology interface sounds"
      },
-     "expected_duration": 16,
-     "word_count": 39,
      "production_notes": "Visualize the sensing and decision-making capabilities of autonomous systems; emphasize safety and technological sophistication"
    },
        "sound_effects": "AI-generated musical notes, creative synthesis sounds, futuristic interface sounds"
      },
-     "expected_duration": 14,
-     "word_count": 35,
      "production_notes": "Balance technological optimism with realistic representation; showcase creative applications that viewers might not have considered"
    },
        "sound_effects": "Subtle ambient sounds suggesting human activity and technology coexistence"
      },
-     "expected_duration": 14,
-     "word_count": 36,
      "production_notes": "End on a thoughtful note that invites viewer consideration; emphasize human agency in shaping AI's future without being preachy"
    }
```

---

I've removed all the word count and duration fields from the Scene Segmentation agent as requested. Now the agent will focus solely on:

1. Identifying natural scene boundaries
2. Extracting exact narration text
3. Generating visual suggestions
4. Developing audio recommendations
5. Ensuring logical scene flow and segmentation

The n8n JavaScript code node can handle the calculation logic for:
- Counting words in each scene's narration text
- Calculating durations based on the formula word_count / 2.5

This separation of concerns allows the AI agent to focus on creative and analytical tasks while ensuring precise calculations are handled consistently by your n8n workflow.

---

_**User**_

What type of node should be used in the workflow to depict the new code node? Don't make the change yet.

---

_**Assistant**_

Based on the workflow diagram and node types defined in the document, the new code node for calculating word count and duration should be classified as an "Integration" node type. This would fit into the system as:

1. **Node Type:** Integration
2. **Service:** n8n-CodeFunction (or similar descriptive name)
3. **Input:** Scene Blueprint (from the Scene Segmentation node)
4. **Output:** Enhanced Scene Blueprint (with calculated word_count and expected_duration fields)

This node would process the Scene Blueprint data, count words in each scene's narration text, calculate durations using the word_count/2.5 formula, and output an enhanced version of the Scene Blueprint with these calculations added.

In the workflow diagram, it would use the blue color coding designated for Integration nodes and would sit between the Scene Segmentation node and any nodes that consume the Scene Blueprint.

---

_**User**_

OK I need you to update the workflow to reflect the addiotion of the code node here that adds to two fields; word_count and expected_duration using a javascript snippet. Similarly, we need the same thing after the Shot Segmentation node. Update the workflow accordingly.

---

_**Assistant**_

I'll update the workflow to incorporate the two new code nodes for calculating word count and duration - one after Scene Segmentation and another after Shot Segmentation.

---

```diff
          based on topic transitions, tone changes, or subject shifts, and enhances each segment with metadata including pacing, visual and audio suggestions,
          and editorial context for production. Preserves exact narration text with proper formatting and punctuation while maintaining paragraph structure.
-         Calculates expected scene duration using industry-standard pacing (approx. 150 words per minute) and ensures logical scene flow and narrative continuity.
          Creates a structured JSON output used by multiple downstream nodes including Shot Segmentation, Character Reference Selection, Audio Generation, and Music Selection.
      </p>
+ 
+     <h4 id="scene-metrics-node">4.1.1b Scene Metrics Calculator</h4>
+     <p><strong>Node Type:</strong> Integration<br>
+         <strong>Service:</strong> n8n-CodeFunction (JavaScript)<br>
+         <strong>Input:</strong> <a href="#scene-blueprint">Scene Blueprint</a> (from Scene Segmentation)<br>
+         <strong>Output:</strong> <a href="#scene-blueprint">Enhanced Scene Blueprint</a><br>
+         <strong>Description:</strong> Processes the Scene Blueprint, calculates word count for each scene's narration text, and computes expected duration (in seconds) using the formula word_count / 2.5. The node adds these two fields to each scene object while preserving all other scene metadata. This calculation ensures accurate timing estimates for downstream production planning. The JavaScript function parses each scene's narration text, counts words, performs the duration calculation, and returns the enhanced blueprint for use by downstream nodes.
+     </p>
  
      <h4 id="shot-segmentation-node">4.1.2 Shot Segmentation</h4>
          downstream production processes.
      </p>
+ 
+     <h4 id="shot-metrics-node">4.1.2b Shot Metrics Calculator</h4>
+     <p><strong>Node Type:</strong> Integration<br>
+         <strong>Service:</strong> n8n-CodeFunction (JavaScript)<br>
+         <strong>Input:</strong> <a href="#shot-plan">Shot Plan</a> (from Shot Segmentation)<br>
+         <strong>Output:</strong> <a href="#shot-plan">Enhanced Shot Plan</a><br>
+         <strong>Description:</strong> Similar to the Scene Metrics Calculator, this node processes the Shot Plan data to calculate word count and expected duration for each shot. For shots containing narration text (primarily A-roll shots), it counts words in the narration_text field and calculates expected duration using the same word_count / 2.5 formula. For B-roll shots without narration, it maintains the original duration estimates. The JavaScript function handles these calculations and returns an enhanced Shot Plan with the additional metrics for downstream production planning.
+     </p>
  
      <h4 id="broll-ideation-node">4.1.3 B-Roll Ideation</h4>
          <strong>Subtype:</strong> JSON<br />
          <strong>Description:</strong> Breakdown of the script into distinct scenes with associated metadata.<br>
-         <strong>Generated By:</strong> <a href="#scene-segmentation-node">Scene Segmentation</a><br>
+         <strong>Generated By:</strong> <a href="#scene-segmentation-node">Scene Segmentation</a>, enhanced by <a href="#scene-metrics-node">Scene Metrics Calculator</a><br>
          <strong>Used By:</strong> <a href="#shot-segmentation-node">Shot Segmentation</a>, <a href="#character-reference-node">Character Reference Selection</a>, <a href="#audio-generation-node">Audio Generation</a>, <a href="#music-selection-node">Music Selection</a>
      </p>
              <td>Object containing background_music and sound_effects suggestions</td>
          </tr>
+         <tr>
+             <td>word_count</td>
+             <td>number</td>
+             <td>Number of words in the scene narration text (added by Scene Metrics Calculator)</td>
+         </tr>
          <tr>
              <td>expected_duration</td>
              <td>number</td>
-             <td>Estimated duration of the scene in seconds</td>
+             <td>Estimated duration of the scene in seconds, calculated as word_count / 2.5 (added by Scene Metrics Calculator)</td>
          </tr>
          <tr>
          <strong>Subtype:</strong> JSON<br>
          <strong>Description:</strong> Breakdown of scenes into individual shots with detailed specifications for visual pacing, narrative rhythm, and content classification.<br>
-         <strong>Generated By:</strong> <a href="#shot-segmentation-node">Shot Segmentation</a><br>
+         <strong>Generated By:</strong> <a href="#shot-segmentation-node">Shot Segmentation</a>, enhanced by <a href="#shot-metrics-node">Shot Metrics Calculator</a><br>
          <strong>Used By:</strong> <a href="#broll-ideation-node">B-Roll Ideation</a>, <a href="#audio-generation-node">Audio Generation</a>, <a href="#sfx-generation-node">Sound Effects Generation</a>
      </p>
          %% Documents using speech bubble style nodes
          A>"Video Script"]:::document ---> B
-         B[Scene Segmentation]:::aiAgent ---> C
+         B[Scene Segmentation]:::aiAgent ---> B1
+         B1[Scene Metrics Calculator]:::integration ---> C
          C>"Scene Blueprint"]:::document ---> D
          C ---> Z
          C ---> P
          C ---> BM
-         D[Shot Segmentation]:::aiAgent ---> E
+         D[Shot Segmentation]:::aiAgent ---> D1
+         D1[Shot Metrics Calculator]:::integration ---> E
          E>"Shot Plan"]:::document ---> F
          E ---> P
          click A href "#video-script" "Go to Video Script"
          click B href "#scene-segmentation-node" "Go to Scene Segmentation"
+         click B1 href "#scene-metrics-node" "Go to Scene Metrics Calculator"
          click C href "#scene-blueprint" "Go to Scene Blueprint"
          click D href "#shot-segmentation-node" "Go to Shot Segmentation"
+         click D1 href "#shot-metrics-node" "Go to Shot Metrics Calculator"
          click E href "#shot-plan" "Go to Shot Plan"
          click F href "#broll-ideation-node" "Go to B-Roll Ideation"
```

---

I've updated the workflow to include two new code nodes that handle word count and duration calculations:

1. **Scene Metrics Calculator**:
   - Placed immediately after Scene Segmentation
   - Integration node that processes the Scene Blueprint
   - Calculates word_count for each scene's narration text
   - Computes expected_duration as word_count / 2.5
   - Adds these fields to each scene object

2. **Shot Metrics Calculator**:
   - Placed after Shot Segmentation
   - Similar functionality but works on the Shot Plan
   - Handles word counting and duration calculations for each shot
   - For A-roll shots, uses narration text for calculations
   - For B-roll shots without narration, maintains original duration estimates

The workflow diagram has been updated to show these new nodes in the proper sequence, with the appropriate Integration node styling. I've also updated the document specifications to reflect that the Scene Blueprint and Shot Plan are now enhanced by these calculator nodes, and modified the field descriptions to clarify that word_count and expected_duration are added by the calculators.

This approach allows the Scene Segmentation and Shot Segmentation agents to focus on their core responsibilities (identifying boundaries, generating descriptions, etc.) while delegating the calculations to dedicated code nodes, as you requested.

---



---

