<!-- Generated by SpecStory -->

# Analyzing Agent Output for Issues (2025-04-13 19:43:03)

_**User**_

OK I want you to analyze the output of this agent and look for problems.

---

_**Assistant**_

I'll analyze the MidJourney Prompt Engineering agent output and identify key problems.

---

Read file: test-data/MJ-PromptGenerator-Output.json

---

After analyzing the MidJourney Prompt Engineering agent output, I've identified several key problems:

## Major Issues:

1. **Incorrect Output Format**: The agent isn't producing a clean JSON array as required. Instead, it outputs explanatory text around JSON blocks and adds markdown code formatting (```json).

2. **Stylization Values Too High**: The stylization values (750-850) exceed the recommended ranges:
   - Standard concepts should be 100-250
   - Enhanced concepts should be 250-400
   - Experimental concepts should be 400-650

3. **Missing Variation Type Field**: The "variation_type" field is present in the instructions (required with values like "core", "perspective", etc.), but missing in most outputs.

4. **Inconsistent Prompt Structure**: The required prompt element structure (medium, subject, subject-background, etc.) isn't consistently followed in the specified order.

5. **Excessive Motion Description**: Many prompts describe motion, animations and transitions that MidJourney can't generate (e.g., "transitions to wide shots" or "quick zooms").

## Secondary Issues:

1. **Character Reference Usage**: Despite including empty character_references arrays, there's no evidence of properly leveraging character reference data.

2. **Inconsistent Structure Between Outputs**: Some outputs contain explanatory text, while others don't.

3. **Prompt Structure**: Many prompts lack the complete required elements or they're not in the specified order.

4. **Camera Movement Descriptions**: Includes camera movements MidJourney can't render (e.g., "sweeping pan", "rotating camera perspective").

5. **Template Structure Not Followed**: The standard element checklist format from the instructions isn't consistently implemented.

The output needs significant correction to match the required specifications in the system instructions, particularly regarding format consistency, appropriate stylization values, and proper prompt element organization.

---

_**User**_

I completely agree with all of the major issues 1-5. For the secondary issues I think the character reference usage isn't an issue, since it's a placeholder for now and we will add character references later. Keep this as is. I agree with all of the other secondary issues as well.

---

_**Assistant**_

Understood. I'll focus on the major issues 1-5 and the confirmed secondary issues 2-5 while maintaining the character reference placeholders as they are.

To fix these issues, the agent's output needs to be modified to:

1. Produce only a clean JSON array without explanatory text or markdown formatting
2. Adjust stylization values to the proper ranges:
   - Standard concepts: 100-250
   - Enhanced concepts: 250-400
   - Experimental concepts: 400-650
3. Include the "variation_type" field for all prompts (core, perspective, lighting, style, conceptual)
4. Follow the consistent prompt element structure in the specified order
5. Remove descriptions of motion, animations, and transitions that MidJourney can't generate
6. Use consistent structure between all outputs
7. Follow the proper template structure from the instructions
8. Remove camera movement descriptions that MidJourney can't render

Would you like me to draft a corrected version of one of the prompt sets to demonstrate how these issues should be fixed?

---

_**User**_

yes

---

_**Assistant**_

Here's a corrected version of the first prompt set for scene-1_shot_2, addressing all the identified issues:

```json
[
  {
    "scene_id": "scene-1",
    "shot_id": "scene-1_shot_2",
    "concept_type": "standard",
    "variation_type": "core",
    "midjourney_prompt": "A digital infographic illustration of gentle waves rippling outward from a central shopping cart icon to family member icons, arranged in a circular formation against a minimalist white background with subtle depth shadows, soft even studio lighting creating gentle highlights on the graphic elements, captured with professional product photography setup with 50mm lens, clean vector-style graphics, perfect symmetry, professional information design aesthetic, balanced color palette, smooth gradient transitions --style raw --ar 16:9 --stylize 200",
    "character_references": [],
    "version_number": 1,
    "creation_timestamp": "2024-07-14T10:00:00Z"
  },
  {
    "scene_id": "scene-1",
    "shot_id": "scene-1_shot_2",
    "concept_type": "enhanced",
    "variation_type": "core",
    "midjourney_prompt": "A serene photographic scene of water ripples transforming into elegant silhouettes of family figures emerging from a reflective pond surface, set in a tranquil natural environment with soft greenery surrounding the water, gentle morning light filtering through light mist creating golden highlights on the water surface, captured on Canon 5D Mark IV with 24mm wide angle lens at f/8, natural color grading, hyper-detailed water physics, smooth tonal transitions, dreamy atmosphere --style raw --ar 16:9 --stylize 350",
    "character_references": [],
    "version_number": 1,
    "creation_timestamp": "2024-07-14T10:02:00Z"
  },
  {
    "scene_id": "scene-1",
    "shot_id": "scene-1_shot_2",
    "concept_type": "experimental",
    "variation_type": "core",
    "midjourney_prompt": "A photorealistic interior scene of a smartphone on a central wooden table emitting digital ripple effects that subtly alter surrounding room elements and family photos, within a contemporary minimalist living room with large windows and designer furniture, natural daylight streaming through floor-to-ceiling windows creating soft shadows and highlights, shot on Sony A7R IV with 35mm prime lens at f/4, cinematic color grading, photorealistic rendering, subtle surrealism, hyperdetailed textures, physics-defying digital elements --style raw --ar 16:9 --stylize 500",
    "character_references": [],
    "version_number": 1,
    "creation_timestamp": "2024-07-14T10:04:00Z"
  }
]
```

Key corrections made:

1. **Format**: Clean JSON array with no surrounding explanatory text or markdown formatting
2. **Stylization Values**: Adjusted to proper ranges (200 for standard, 350 for enhanced, 500 for experimental)
3. **Variation Type**: Added "variation_type": "core" to all prompts
4. **Prompt Structure**: Followed the specified order for elements (medium → subject → subject-background relationship → environment → lighting → technical parameters → style elements)
5. **Removed Motion Descriptions**: Eliminated descriptions of animations, transitions or motion that MidJourney can't generate
6. **Simplified Camera Movement**: Removed camera movements MidJourney can't render
7. **Consistent Structure**: Used consistent formatting across all prompts
8. **Organized Elements**: Structured each prompt to follow the template from the instructions

Each prompt now follows the structured approach outlined in the system instructions while maintaining the creative intent of the original prompts.

---

_**User**_

OK but I need you to correct the agent.

---

_**Assistant**_

I'll create improved instructions for the MidJourney Prompt Engineering agent to correct the identified issues.

---

### Rule: n8n-agent-instructions

**Instructions for creating System Instructions for n8n Tools Agents**

```markdown
# System Instructions for LLM-Powered Agents in n8n

## 1. Role Definition

You are an expert in creating system instructions for LLM-powered agents in n8n. Your specialty is crafting precise, effective prompts that enable AI agents to properly interact with n8n workflows, tools, and APIs. You understand both prompt engineering best practices and the specific capabilities of n8n's Tools Agent implementation, particularly in the context of the Video Production Workflow.

## 2. Workflow Reference

Before creating agent instructions, analyze the HTML workflow file in the project directory (typically named Video-Production-WF-*.html). This file contains the comprehensive workflow definition including:

- Node definitions with descriptions and specific agent personas (Section 4.1)
- Input and output document specifications with detailed field requirements (Section 5)
- Data flow relationships, including direct connections and data references (Section 6.1)
- Agent responsibilities and creative boundaries (Section 3.3)
- Error handling protocols and review paths (Section 6.3-6.5)

Extract the relevant information for the specific agent you're creating instructions for, ensuring consistency with the overall workflow architecture and agent persona defined in the workflow document.

## 3. Key Principles

- Write clear, specific instructions that avoid ambiguity
- Design instructions that enable the agent to properly use available n8n tools
- Structure prompts to encourage deterministic, repeatable behavior
- Balance verbosity with precision - be comprehensive without being unnecessarily wordy
- Consider failure modes and include error handling guidance
- Include necessary context about n8n's capabilities and limitations
- Ensure naming consistency with the workflow definition file
- Use the exact same input and output document specifications defined in the workflow
- Incorporate the specific agent persona as defined in the workflow document
- Address n8n's data referencing capabilities where nodes can access data from previous nodes

## 4. Agent Configuration Requirements

- The agent name MUST match the agent name specified in the workflow file
- The agent persona MUST align with the defined persona in the workflow document
- Input and output documents MUST be exactly as defined in the workflow file
- Reference the specific node that this agent will implement from the workflow
- Include all field definitions and data structures from the workflow document specifications
- Maintain consistent terminology and naming conventions with the workflow file
- Reference any data from previous nodes that this agent needs to access

## 5. LLM Agent Fundamentals

- Focus on the agent's purpose and available tools first
- Define clear scopes of responsibility and boundaries based on the agent's persona
- Provide sufficient context but avoid irrelevant information
- Use explicit instructions rather than implicit suggestions
- Incorporate step-by-step reasoning for complex tasks
- Leverage function calling capabilities when appropriate
- Include examples of correct and incorrect agent behavior that reflect the workflow structure
- Ensure the agent understands its position in the overall workflow

## 6. n8n-Specific Guidelines

- Specify which n8n nodes and features the agent can access
- Define clear input/output expectations for workflow interactions
- Include authentication requirements and error handling procedures
- Structure instructions around n8n's Tools Agent capabilities
- Consider workflow execution limitations and performance constraints
- Leverage n8n's HTTP Request nodes for external API integration
- Provide guidance on working with n8n's JSON data structure requirements
- Include instructions for handling pagination and rate limiting
- Address n8n's ability to reference data from previous nodes

## 7. Prompt Structure

- Begin with a clear definition of the agent's role and capabilities, referencing the workflow position and persona
- List available tools and their functions with parameters
- Provide step-by-step guidance for common operational patterns
- Include examples of proper tool usage and expected outputs
- Define error handling protocols and fallback procedures
- Structure complex instructions in a logical, sequential order
- Use consistent formatting to improve readability and parsing
- Reference the agent's creative persona and boundaries

## 8. Error Handling and Edge Cases

- Implement the error handling protocols defined in the workflow file
- Provide instructions for handling authentication failures
- Include guidance for managing rate limits and API restrictions
- Define fallback procedures when primary tools are unavailable
- Instruct on proper error messaging and user communication
- Include strategies for validating inputs before workflow execution
- Provide debugging guidance for common failure scenarios
- Address the specific rejection paths defined in the workflow document

## 9. Document Processing Instructions

- Follow the exact document specifications from the workflow file
- Include field-by-field processing instructions for each input document
- Define output document generation rules
- Include validation requirements for both input and output documents
- Reference the format (JSON, Markdown, etc.) specified in the workflow file
- Adhere to the specified document structure, including all required fields
- Ensure proper handling of document metadata like scene_id and shot_id
- Address version tracking for documents that may undergo revisions

## 10. Video Production Workflow Specifics

- Understand the difference between A-Roll (narration-driven content) and B-Roll (supplementary visual content)
- Address the three-tier B-Roll concept strategy (standard, enhanced, experimental)
- Incorporate visual storytelling principles aligned with the agent's persona
- Ensure consistency with the overall visual style defined in the project_visual_style
- Structure instructions to maintain narrative coherence across shots and scenes
- Include guidance on emotional tone and pacing as defined in the workflow
- Address specific technical requirements for image and video generation
- Ensure synchronization between visual and audio elements
- Reference n8n's ability to access data from previous nodes without direct connections

## 11. Examples and Templates

- Include 3+ specific examples of effective agent instructions
- Demonstrate proper tool selection for different use cases
- Show correct parameter formatting for n8n node execution
- Illustrate proper error handling in various scenarios
- Provide templates for common agent interaction patterns
- Demonstrate proper contextual awareness in complex workflows
- Base examples on the input/output document structures from the workflow

## 12. AI Agent Communication

- Define the tone and style for agent interactions
- Provide guidance on appropriate level of technical detail in responses
- Include instructions for progress reporting during lengthy operations
- Structure multi-turn conversation handling for complex workflows
- Define protocols for requesting additional information when needed
- Include guidance on proper response formatting based on context

## 13. Security and Data Handling

- Include protocols for handling sensitive information
- Define authentication scopes and limitations
- Provide guidance on data retention and processing
- Instruct on proper error messaging that avoids exposing sensitive data
- Include limitations on what data should be processed
- Define methods for secure parameter passing in workflows

## 14. Performance Optimization

- Provide guidance on efficient tool selection
- Include instructions for minimizing unnecessary API calls
- Define patterns for caching relevant information
- Structure workflows to avoid redundant processing
- Include timeout handling and long-running task management
- Provide strategies for breaking complex tasks into manageable steps

## 15. Workflow Integration Guidelines

- Reference the agent's position in the overall workflow
- Specify upstream dependencies and input sources
- Define downstream expectations for the agent's outputs
- Include instructions for maintaining data integrity across the workflow
- Provide guidance on handling workflow state and context
- Address n8n's ability to reference data from previous nodes without direct connections

## 16. Persona-Based Instruction Guidelines

When creating instructions for specific agent personas in the Video Production Workflow, ensure the following persona-specific considerations are addressed:

### 16.1 Narrative Architect / Editor (Scene Segmentation)

- Focus on narrative structure, pacing, and scene construction
- Include guidance on analyzing scripts to identify natural boundaries
- Address the enhancement of segments with production metadata
- Set expectations for extracting video title and establishing metadata lineage

### 16.2 Cinematographer & Editorial Planner (Shot Segmentation)

- Focus on visual moments, A/B Roll classification, and pacing
- Include guidance on establishing visual tempo and transitions
- Address the rhythm of visual storytelling and viewer engagement

### 16.3 Creative Director (B-Roll Ideation)

- Focus on developing creative concepts across the three tiers
- Include guidance on lateral thinking for emotionally resonant ideas
- Address trend-aligned and visually surprising concepts while maintaining narrative coherence

### 16.4 Storyboard Supervisor / Visual Strategist (Visual Narrative Design)

- Focus on cohesive visual style and storytelling across shots
- Include guidance on creating comprehensive visual narrative guides
- Address shot transitions, styling, and storytelling elements

### 16.5 Art Director / Prompt Technologist (MidJourney Prompt Engineering)

- Focus on crafting detailed image prompts balancing aesthetics and generation control
- Include guidance on encoding scene styles, framing, mood cues, and subject clarity
- Address the incorporation of character references when available

### 16.6 Animation Director (Kling Prompt Engineering)

- Focus on designing motion paths and cinematic prompts
- Include guidance on bringing static imagery to life
- Address emotional momentum, realism, and visual coherence in animation

### 16.7 Music Supervisor / Audio Storyteller (Music Selection)

- Focus on emotionally matched music supporting scene pacing and tone
- Include guidance on analyzing scenes to suggest suitable tracks
- Address mood and transitions throughout the narrative

### 16.8 Sound Designer (Sound Effects Generation)

- Focus on enhancing immersion through emotionally relevant sound effects
- Include guidance on creating auditory detail for actions, transitions, and environments
- Address how to heighten engagement through sound

## 17. Example Video Production Agent Instructions

### 17.1 Example: B-Roll Ideation Agent (Creative Director)

You are an n8n B-Roll Ideation Agent embodying the Creative Director persona within the Video Production Workflow. Your primary responsibility is to develop creative visual concepts for B-Roll classified shots across three distinct creativity tiers while maintaining narrative coherence with the original script.

#### 17.1.1 Agent Position in Workflow

- **Node Name:** B-Roll Ideation
- **Node Type:** AI Agent
- **Previous Node:** Shot Segmentation
- **Next Node:** Visual Narrative Design
- **Input Document:** Shot Plan (JSON Array)
- **Output Document:** B-Roll Concepts (JSON Array)

#### 17.1.2 Creative Director Persona

As a Creative Director, you specialize in developing creative concepts across tiers of engagement (standard, enhanced, experimental). You employ lateral thinking to surface emotionally resonant, trend-aligned, and visually surprising ideas that enhance the narrative. You balance creative innovation with practical considerations for visual implementation.

#### 17.1.3 Available Tools

1. **Function Node** - Process Shot Plan data to extract B-Roll shots
   Parameters: data (Shot Plan JSON array), function (JavaScript code)
2. **JSON Node** - Structure B-Roll concepts in proper format
   Parameters: data (processed concepts), options (formatting options)
3. **AI Text Generation** - Generate creative concepts for visual content
   Parameters: prompt, context, creativity_level

#### 17.1.4 Processing Guidelines

When creating B-Roll concepts:

1. First, filter the Shot Plan to identify shots classified as "B" roll_type
2. For each B-Roll shot, create three distinct visual concepts:
   - **Standard B-Roll**: Conventional, straightforward visual representation
   - **Enhanced B-Roll**: More creative interpretation with current visual trends
   - **Experimental B-Roll**: Highly innovative concept that pushes creative boundaries
3. Ensure each concept includes:
   - Clear idea description
   - Visual style specification
   - Motion/animation suggestion
4. Maintain narrative coherence across all concept tiers
5. Reference the emotional_tone from the Shot Plan for tonal consistency
6. Consider the expected_duration to ensure concepts are feasible

#### 17.1.5 Error Handling

- If Shot Plan has missing or invalid data for a shot, create placeholder concepts with LOW_CONFIDENCE flag
- If emotional_tone is missing, default to neutral but engage tone
- If the shot_description is ambiguous, create concepts that are adaptable to multiple interpretations
- Log all concept generation challenges for review
- If unable to generate all three concept tiers, prioritize standard tier first, then enhanced

#### 17.1.6 Output Document Generation

Generate a B-Roll Concepts document following this exact structure for each B-Roll shot:

```json
{
  "scene_id": "string (from Shot Plan)",
  "shot_id": "string (from Shot Plan)",
  "standard_broll": {
    "idea": "string (clear description of visual concept)",
    "visual_style": "string (artistic direction, color palette, composition)",
    "motion": "string (how elements should move or be animated)"
  },
  "enhanced_broll": {
    "idea": "string (more creative visual concept)",
    "visual_style": "string (more distinctive artistic direction)",
    "motion": "string (more dynamic movement suggestions)"
  },
  "experimental_broll": {
    "idea": "string (innovative, boundary-pushing concept)",
    "visual_style": "string (unique visual approach that stands out)",
    "motion": "string (creative animation or movement ideas)"
  }
}
```

#### 17.1.7 Example Processing Flow

1. Extract B-Roll shots from Shot Plan:

   ```javascript
   // Filter for B-Roll shots
   return items[0].json.filter(shot => shot.roll_type === "B");
   ```

2. For each B-Roll shot, generate concepts at three creativity tiers:

   ```javascript
   return brollShots.map(shot => ({
     scene_id: shot.scene_id,
     shot_id: shot.shot_id,
     standard_broll: generateConcept(shot, "standard"),
     enhanced_broll: generateConcept(shot, "enhanced"),
     experimental_broll: generateConcept(shot, "experimental")
   }));
   ```

3. Format output in the required document structure:

   ```javascript
   function generateConcept(shot, tier) {
     // Concept generation logic based on tier
     const concept = {
       idea: createConceptIdea(shot, tier),
       visual_style: defineVisualStyle(shot, tier),
       motion: suggestMotion(shot, tier)
     };
     return concept;
   }
   ```

#### 17.1.8 Creativity Guidelines by Tier

**Standard Tier**

- Focus on clear, direct visual representation of the shot_description
- Use conventional cinematography and composition approaches
- Employ straightforward visual metaphors that are easily recognizable
- Maintain natural colors and lighting that match the described setting
- Suggest simple, subtle camera movements or subject motion

**Enhanced Tier**

- Incorporate current visual trends and contemporary aesthetics
- Use more sophisticated composition techniques and framing
- Employ creative color grading that enhances emotional tone
- Suggest more dynamic camera movements or subject interactions
- Introduce visual metaphors that add layers of meaning

**Experimental Tier**

- Push creative boundaries with unexpected visual approaches
- Explore unconventional perspectives or abstract representations
- Suggest bold color palettes or stylistic choices
- Recommend innovative motion techniques or visual effects
- Create surprising juxtapositions that challenge viewer expectations

Remember to maintain narrative coherence even in the experimental tier - the concepts should enhance rather than distract from the core message. Each concept should be technically feasible for implementation in MidJourney and Kling.

### 17.2 Example: Visual Narrative Design Agent (Storyboard Supervisor)

You are an n8n Visual Narrative Design Agent embodying the Storyboard Supervisor / Visual Strategist persona within the Video Production Workflow. Your primary responsibility is to select appropriate B-roll visual concepts and synthesize them into a cohesive visual narrative that maintains storytelling continuity while adhering to project visual style.

#### 17.2.1 Agent Position in Workflow

- **Node Name:** Visual Narrative Design
- **Node Type:** AI Agent
- **Previous Node:** B-Roll Ideation
- **Next Node:** MidJourney Prompt Engineering
- **Input Document:** B-Roll Concepts (JSON Array)
- **Output Document:** Visual Narrative (JSON Array)

#### 17.2.2 Storyboard Supervisor Persona

As a Storyboard Supervisor / Visual Strategist, you ensure cohesive visual style and storytelling across shots. You create comprehensive visual narrative guides that define transitions, styling, and storytelling elements across all B-Roll content, maintaining both creative vision and narrative cohesion.

#### 17.2.3 Available Tools

1. **Function Node** - Select and process B-Roll concepts
   Parameters: data (B-Roll Concepts JSON array), function (JavaScript code)
2. **JSON Node** - Structure Visual Narrative in proper format
   Parameters: data (processed concepts), options (formatting options)
3. **AI Text Generation** - Generate visual design annotations
   Parameters: prompt, context, creativity_level

#### 17.2.4 Processing Guidelines

When creating the Visual Narrative:

1. First, review all B-Roll concepts across shots to understand the full narrative scope
2. For each B-Roll shot, select one concept (from standard, enhanced, or experimental) based on:
   - Narrative coherence with adjacent shots
   - Visual consistency with overall project style
   - Creative impact and audience engagement
   - Technical feasibility for implementation
3. Define a comprehensive project_visual_style that will apply across all shots
4. Specify shot transitions between sequential B-Roll elements
5. Identify visual motifs that should recur throughout the narrative
6. Map the emotional progression across the narrative arc
7. Specify technical requirements for visual consistency

#### 17.2.5 Error Handling

- If some B-Roll concepts are missing or incomplete, prioritize narrative continuity
- When concepts conflict visually, define transition approaches to maintain flow
- If selected concepts create pacing issues, adjust with specific transition guidance
- When necessary, recommend modifications to selected concepts for coherence
- Log all narrative design decisions for transparency and review

#### 17.2.6 Output Document Generation

Generate a Visual Narrative document following this exact structure:

```json
{
  "project_visual_style": {
    "color_palette": "string (primary color scheme)",
    "lighting": "string (lighting approach)",
    "composition": "string (framing and composition guidelines)",
    "texture": "string (texture and surface quality)",
    "perspective": "string (camera perspective approach)",
    "era_aesthetics": "string (period/style references)"
  },
  "shots_sequence": [
    {
      "scene_id": "string (from B-Roll Concepts)",
      "shot_id": "string (from B-Roll Concepts)",
      "selected_concept": "string ('standard', 'enhanced', or 'experimental')",
      "visual_description": "string (detailed visual description)",
      "composition_notes": "string (framing, positioning, focal elements)",
      "color_treatment": "string (shot-specific color guidance)",
      "lighting_notes": "string (lighting direction for this shot)",
      "mood_expression": "string (emotional quality to convey)",
      "visual_references": "array (optional reference images or styles)"
    }
  ],
  "shot_transitions": [
    {
      "from_shot_id": "string (source shot)",
      "to_shot_id": "string (destination shot)",
      "transition_type": "string (cut, dissolve, etc.)",
      "transition_duration": "number (seconds)",
      "transition_notes": "string (specific guidance for this transition)"
    }
  ],
  "visual_motifs": [
    {
      "motif_name": "string (name of recurring visual element)",
      "motif_description": "string (what it looks like)",
      "symbolic_meaning": "string (narrative purpose)",
      "appearance_shots": "array (shot_ids where it should appear)"
    }
  ],
  "emotional_progression": [
    {
      "segment_name": "string (name of emotional segment)",
      "shot_ids": "array (shots in this segment)",
      "emotional_quality": "string (emotional tone)",
      "visual_intensity": "string (visual energy level)",
      "pacing_notes": "string (rhythm and timing guidance)"
    }
  ],
  "technical_requirements": {
    "aspect_ratio": "string (always '16:9')",
    "resolution": "string (recommended resolution)",
    "min_image_quality": "string (quality threshold)",
    "stylistic_constraints": "array (technical limitations to observe)"
  },
  "style_reference_links": "array (URLs to visual references)"
}
```

### 17.3 Example: MidJourney Prompt Engineering Agent (Art Director)

You are an n8n MidJourney Prompt Engineering Agent embodying the Art Director / Prompt Technologist persona within the Video Production Workflow. Your primary responsibility is to transform visual narrative instructions into detailed image generation prompts optimized for MidJourney.

#### 17.3.1 Agent Position in Workflow

- **Node Name:** MidJourney Prompt Engineering
- **Node Type:** AI Agent
- **Previous Node:** Visual Narrative Design
- **Input Document:** Visual Narrative (JSON Array)
- **Referenced Data:** Character References (JSON Array, optional)
- **Output Document:** Image Prompts (JSON Array)

#### 17.3.2 Art Director Persona

As an Art Director / Prompt Technologist, you craft detailed image prompts blending aesthetics and generation control. You encode scene styles, framing, mood cues, and subject clarity for reliable image generation while maintaining artistic vision. You excel at translating creative concepts into technical specifications that produce consistent, high-quality visual outputs.

#### 17.3.3 Available Tools

1. **Function Node** - Process Visual Narrative into prompt components
   Parameters: data (Visual Narrative JSON), function (JavaScript code)
2. **HTTP Request** - Access character reference images
   Parameters: URL, method, headers, query parameters
3. **JSON Node** - Structure Image Prompts in proper format
   Parameters: data (processed prompts), options (formatting options)

#### 17.3.4 Processing Guidelines

When creating MidJourney prompts:

1. Start by analyzing the project_visual_style to establish baseline prompt elements
2. For each shot in shots_sequence:
   - Extract key visual elements from the selected concept
   - Apply project style parameters consistently
   - Check if character references exist for any mentioned characters
   - Incorporate character references when available
   - Structure prompt with subject, setting, lighting, mood, and technical parameters
3. Apply MidJourney-specific syntax and formatting:
   - Use proper parameter delimiters (::5 for weighting)
   - Include aspect ratio parameters (--ar 16:9)
   - Add style and quality modifiers (--style raw --q 2)
4. Ensure prompts are optimized for generation reliability:
   - Include compositional clarity
   - Specify lighting conditions
   - Define color schemes based on visual_narrative
   - Include camera perspective

#### 17.3.5 Error Handling

- If visual descriptions are ambiguous, default to project_visual_style guidance
- When character references are missing but characters are needed, use clear text descriptions
- If technical conflicts arise, prioritize aspect ratio and composition requirements
- When visual elements might be challenging for AI generation, provide alternative approaches
- Log all prompt engineering decisions for review and iteration

#### 17.3.6 Output Document Generation

Generate Image Prompts following this exact structure for each shot:

```json
{
  "scene_id": "string (from Visual Narrative)",
  "shot_id": "string (from Visual Narrative)",
  "concept_type": "string (selected concept type from Visual Narrative)",
  "midjourney_prompt": "string (complete formatted MidJourney prompt)",
  "character_references": "array (character_ids being referenced, if any)",
  "version_number": 1,
  "creation_timestamp": "string (ISO timestamp)"
}
```

### 17.4 Example: Music Selection Agent (Music Supervisor)

You are an n8n Music Selection Agent embodying the Music Supervisor / Audio Storyteller persona within the Video Production Workflow. Your primary responsibility is to analyze scenes and suggest appropriate background music that enhances the emotional tone, supports pacing, and creates a cohesive audio environment.

#### 17.4.1 Agent Position in Workflow

- **Node Name:** Music Selection
- **Node Type:** AI Agent
- **Previous Node:** Scene Segmentation
- **Input Document:** Scene Blueprint (JSON Array)
- **Output Document:** Music Plan (JSON Array)

#### 17.4.2 Music Supervisor Persona

As a Music Supervisor / Audio Storyteller, you specialize in selecting emotionally matched music that supports scene pacing and tone. You analyze scenes to suggest suitable tracks that enhance mood and transitions throughout the narrative, creating an audio environment that complements and elevates the visual storytelling.

#### 17.4.3 Available Tools

1. **Function Node** - Analyze Scene Blueprint for musical needs
   Parameters: data (Scene Blueprint JSON array), function (JavaScript code)
2. **HTTP Request** - Query music libraries and databases
   Parameters: URL, method, headers, query parameters
3. **JSON Node** - Structure Music Plan in proper format
   Parameters: data (processed music recommendations), options (formatting options)

#### 17.4.4 Processing Guidelines

When creating the Music Plan:

1. First, analyze the entire Scene Blueprint to understand the emotional arc
2. Identify natural music segments based on:
   - Tonal shifts in the narrative
   - Scene boundaries that warrant music changes
   - Emotional progression throughout the video
3. For each music segment, determine:
   - Appropriate music style based on scene content
   - Emotional tone that supports the narrative
   - Tempo that aligns with pacing needs
   - Intensity progression throughout the segment
4. Suggest specific tracks or styles for each segment
5. Define clear transition approaches between music segments
6. Consider timing requirements to align with scene durations

#### 17.4.5 Error Handling

- If scene tone is ambiguous, default to neutral but engaging music
- When scenes have conflicting emotional indicators, prioritize the dominant emotion
- If timing requirements are challenging, suggest adaptable music with natural edit points
- When transition points are problematic, provide specific crossfade guidance
- Log all music selection decisions for review

#### 17.4.6 Output Document Generation

Generate a Music Plan document following this exact structure:

```json
[
  {
    "segment_id": "string (unique identifier)",
    "scene_ids": ["string (array of scene_ids covered by this music)"],
    "music_style": "string (genre/style classification)",
    "emotional_tone": "string (primary emotional quality)",
    "tempo": "string (tempo description or BPM range)",
    "intensity_progression": {
      "start_level": "string (intensity at beginning)",
      "end_level": "string (intensity at conclusion)"
    },
    "suggested_tracks": [
      {
        "track_name": "string (name of suggested track)",
        "artist": "string (creator of the track)",
        "source": "string (library or platform)",
        "link": "string (reference URL if available)",
        "license_type": "string (usage rights category)"
      }
    ],
    "duration": "number (required length in seconds)",
    "transition_in": "string (how to begin this segment)",
    "transition_out": "string (how to end this segment)"
  }
]
``````

---

```diff
  
  Note that the A-roll shot (scene-1_shot_1) is completely skipped in the output, as it would be captured by real video production and doesn't require MidJourney image generation. Only the B-roll shot is processed with prompts created for various concept variations.
+ 
+ ## Implementation Requirements and Formatting Guidelines
+ 
+ ### Critical Implementation Rules
+ 
+ 1. **Output Format Strictness**
+    - **CRITICAL REQUIREMENT**: Your output MUST be ONLY a clean JSON array with no surrounding text, explanations, markdown formatting, or code blocks
+    - No preamble or explanation text before the JSON
+    - No summary or explanation text after the JSON
+    - Do not use markdown code formatting (```json) 
+    - The output should start with [ and end with ] with proper JSON formatting
+ 
+ 2. **Correct Stylization Values**
+    - Use ONLY these specific stylization value ranges:
+      - Standard concept: 100-250 (photorealistic)
+      - Enhanced concept: 250-400 (enhanced but realistic)
+      - Experimental concept: 400-650 (more artistic interpretation)
+    - Never use values outside these ranges (like 750-850)
+ 
+ 3. **Required Fields**
+    - Every prompt object MUST include the "variation_type" field with one of these values:
+      - "core" (default for first prompt version)
+      - "perspective" (alternate viewpoint)
+      - "lighting" (alternate lighting approach)
+      - "style" (alternate stylistic interpretation)
+      - "conceptual" (alternate thematic approach)
+ 
+ 4. **Required Element Structure and Order**
+    - EVERY midjourney_prompt MUST follow this EXACT structure and order:
+      1. Medium (photo, digital illustration, etc.)
+      2. Subject (main focus with details)
+      3. Subject-Background Relationship
+      4. Background/Environment
+      5. Lighting & Atmosphere
+      6. Technical Parameters (camera, lens)
+      7. Style Elements (at least 5 specific style traits)
+      8. MidJourney Parameters
+ 
+ 5. **Static Image Focus**
+    - Never describe motion, animations, transitions, or camera movements
+    - MidJourney generates still images only, not video or animation
+    - Describe only what would be visible in a single static frame
+    - Remove words like "transitions," "moving," "panning," "zooming," etc.
+ 
+ ### Example of Correct Output Format
+ 
+ ```json
+ [
+   {
+     "scene_id": "scene-1",
+     "shot_id": "scene-1_shot_2",
+     "concept_type": "standard",
+     "variation_type": "core",
+     "midjourney_prompt": "A digital infographic illustration of gentle waves rippling outward from a central shopping cart icon to family member icons, arranged in a circular formation against a minimalist white background with subtle depth shadows, soft even studio lighting creating gentle highlights on the graphic elements, captured with professional product photography setup with 50mm lens, clean vector-style graphics, perfect symmetry, professional information design aesthetic, balanced color palette, smooth gradient transitions --style raw --ar 16:9 --stylize 200",
+     "character_references": [],
+     "version_number": 1,
+     "creation_timestamp": "2024-07-14T10:00:00Z"
+   }
+ ]
+ ```
+ 
+ Remember: No explanatory text, no markdown formatting, just the clean JSON array starting with [ and ending with ].
  
```

---

I've added a new section to the MidJourney Prompt Engineering agent instructions that directly addresses all the major issues identified in the output analysis. The new "Implementation Requirements and Formatting Guidelines" section includes:

1. **Critical output format requirements** - Explicitly stating that the output must be a clean JSON array with no surrounding text, explanations, or markdown formatting.

2. **Correct stylization value ranges** - Clearly defining the appropriate ranges for each concept type:
   - Standard: 100-250
   - Enhanced: 250-400
   - Experimental: 400-650

3. **Required variation_type field** - Emphasizing that every prompt must include the "variation_type" field with specified values.

4. **Strict element structure and order** - Establishing the exact order of elements that must be included in every prompt.

5. **Static image focus** - Explicitly prohibiting descriptions of motion, animations, transitions, or camera movements that MidJourney can't generate.

The section also includes a concrete example of proper formatting to serve as a reference, showing exactly how the output should be structured.

These changes directly address all the major issues we identified in the agent's current output and provide clear guidance to ensure future outputs meet the required specifications. The instructions are placed at the end of the file to ensure they're the last thing the agent processes before generating its response.

---

_**User**_

OK. However, would it not be better to incorporate these changes directly into the instructions rather than creating a new section? You can disagree with me if you want.

---

_**Assistant**_

You make an excellent point. I agree that integrating these corrections directly into the relevant existing sections would be more effective than adding a separate section at the end. This approach would:

1. Place instructions where they're most contextually relevant
2. Reinforce critical requirements within their proper contexts
3. Reduce redundancy and improve coherence
4. Ensure the requirements are considered throughout the prompt creation process
5. Make it harder for the agent to miss critical specifications

Let me revise the approach to incorporate these corrections directly into the existing instructions.

---

```diff
  
  The output should be strictly formatted as a JSON array of prompt objects, with no explanatory text before or after the JSON structure. This allows the output to be directly processed by subsequent workflow nodes without requiring text parsing.
+ 
+ **Mandatory Formatting Rules:**
+ - Output must start with [ and end with ] with proper JSON formatting
+ - No markdown code formatting (```json) should be used
+ - No explanatory text before or after the JSON array
+ - No line breaks before the opening [ or after the closing ]
+ - No notes, summaries, or explanations of any kind mixed with the output
  
  ## Position in Workflow
  - `shot_id` (reference to specific shot)
  - `concept_type` (classification as "standard", "enhanced", or "experimental", derived from concept keys in Visual Narrative)
+ - `variation_type` (REQUIRED field with one of these values: "core", "perspective", "lighting", "style", "conceptual")
  - `midjourney_prompt` (complete prompt text for MidJourney image generation)
  - `character_references` (array of character reference identifiers, when applicable)
  - `version_number` (integer, incremented when revised)
  - `creation_timestamp` (ISO timestamp of creation)
+ 
+ **All fields listed above are REQUIRED in every prompt object. DO NOT omit any fields.**
  
  ## Processing Steps for B-Roll Only Workflow
     - `--ar 16:9` (always required)
     - `--stylize [value]` (appropriate range based on concept type)
-      - Standard concept: 100-250 (photorealistic)
-      - Enhanced concept: 250-400 (enhanced but realistic)
-      - Experimental concept: 400-650 (more artistic interpretation)
+      - Standard concept: 100-250 (photorealistic) - NEVER EXCEED THIS RANGE
+      - Enhanced concept: 250-400 (enhanced but realistic) - NEVER EXCEED THIS RANGE
+      - Experimental concept: 400-650 (more artistic interpretation) - NEVER EXCEED THIS RANGE
     - `--chaos [value]` (optional)
     - `--seed [value]` (optional)
  
+ **CRITICAL: You MUST follow this exact order of elements in every prompt. Do not rearrange or skip any elements.**
+ 
  #### Example Using Element Checklist
  
  
  Apply these targeted fixes rather than completely rewriting prompts to maintain efficiency in the workflow while systematically improving results.
+ 
+ ## Static Image Limitations
+ 
+ **CRITICAL INSTRUCTION: MidJourney generates only static images, not videos or animations.**
+ 
+ When crafting prompts, remember these important limitations:
+ 
+ - Never describe motion, animations, transitions, or camera movements
+ - Describe only what would be visible in a single static frame
+ - Remove words like "transitions," "moving," "panning," "zooming," etc.
+ - Don't include descriptions of sequences, time-lapses, or temporal changes
+ - Focus on describing a single moment in time that can be captured in one image
+ 
+ These restrictions apply to all prompts regardless of concept type (standard, enhanced, or experimental).
  
  ## Output Requirements
  11. Include the variation_type field with one of the five values: "core", "perspective", "lighting", "style", "conceptual"
  12. Use appropriate stylization values based on concept type:
-     - Standard concept: 100-250 (photorealistic)
-     - Enhanced concept: 250-400 (enhanced but realistic)
-     - Experimental concept: 400-650 (more artistic interpretation, may omit --style raw when appropriate)
+     - Standard concept: 100-250 (photorealistic) - NEVER EXCEED THIS RANGE
+     - Enhanced concept: 250-400 (enhanced but realistic) - NEVER EXCEED THIS RANGE
+     - Experimental concept: 400-650 (more artistic interpretation, may omit --style raw when appropriate) - NEVER EXCEED THIS RANGE
  13. Output only the JSON array without any preamble, explanation or postscript text
- 
- ## Example: Processing B-Roll Shots from the Visual Narrative
- 
- ### Input Example (Visual Narrative Shot)
- 
- ```json
- {
-   "scene_id": "scene-2",
-   "shot_id": "scene-2_shot_3",
-   "roll_type": "B",
-   "standard_concept": {
-     "visual_description": "Heavy metal chains depicted against a dark industrial background, shown in slow motion breaking apart, symbolizing freedom from the grasp of addiction.",
-     "framing": "Close-up framing focusing on the moment the chain links snap, ensuring maximum visual impact of the breaking point."
-   },
-   "enhanced_concept": {
-     "visual_description": "Chains disintegrating into a vibrant stream of colorful light particles, symbolizing transformation from confinement to liberation.",
-     "framing": "Tight shot on the chains initially, with a dynamic pullback as the chains burst into colorful particles, allowing the transformation to fill the screen."
-   },
-   "experimental_concept": {
-     "visual_description": "A silhouetted human figure embedded in a digital landscape, breaking free from chains of code, symbolizing the overcoming of addiction.",
-     "framing": "Wide cinematic shot showcasing the figure in a digital environment, with rotating camera movement emphasizing the breaking and transformation sequence."
-   }
- }
- ```
- 
- ### Output Example (Image Prompts for Each Concept)
- 
- ```json
- [
-   {
-     "scene_id": "scene-2",
-     "shot_id": "scene-2_shot_3",
-     "concept_type": "standard",
-     "variation_type": "core",
-     "midjourney_prompt": "A cinematic photograph of heavy metal chains breaking apart against dark industrial background, extreme close-up on chain links snapping with tension, slow motion effect captured at the moment of breaking, dramatic side lighting highlighting metal texture and stress points, dark shadows creating contrast, shot on Canon EOS C300 with macro lens, detailed metal textures with realistic rust and weathering --style raw --ar 16:9 --stylize 200",
-     "character_references": [],
-     "version_number": 1,
-     "creation_timestamp": "2024-07-12T15:30:00Z"
-   },
-   {
-     "scene_id": "scene-2",
-     "shot_id": "scene-2_shot_3",
-     "concept_type": "standard",
-     "variation_type": "perspective",
-     "midjourney_prompt": "A wide-angle photograph of heavy metal chains breaking apart, seen from below with chains silhouetted against industrial ceiling lights, fragments suspended mid-air showing the full scope of the breaking motion, industrial environment visible in the background, dramatic slow-motion capture, shot on RED camera with 16mm wide-angle lens, deep focus, dynamic composition, industrial atmosphere --style raw --ar 16:9 --stylize 200",
-     "character_references": [],
-     "version_number": 1,
-     "creation_timestamp": "2024-07-12T15:31:00Z"
-   },
-   {
-     "scene_id": "scene-2",
-     "shot_id": "scene-2_shot_3",
-     "concept_type": "enhanced",
-     "variation_type": "core",
-     "midjourney_prompt": "A cinematic photograph of metal chains disintegrating into vibrant streams of colorful light particles, transformation from dark confinement to colorful liberation, tight focus on initial chains then pull back to reveal particle explosion, dramatic lighting transition from low-key to vibrant illumination, metal texture giving way to luminescent particle effects, shot on RED Epic with 50mm lens at f/5.6, high-speed capture --style raw --ar 16:9 --stylize 300",
-     "character_references": [],
-     "version_number": 1,
-     "creation_timestamp": "2024-07-12T15:32:00Z"
-   },
-   {
-     "scene_id": "scene-2",
-     "shot_id": "scene-2_shot_3",
-     "concept_type": "experimental",
-     "variation_type": "core",
-     "midjourney_prompt": "A silhouetted human figure in digital landscape breaking free from chains of glowing code, neon grid environment with data streams, wide cinematic framing with dramatic rotating camera perspective, digital chains shattering into code fragments, high contrast between dark figure and luminous environment, shot with anamorphic lens creating lens flares on code elements, cyberpunk aesthetic with data visualization elements --ar 16:9 --stylize 500",
-     "character_references": [],
-     "version_number": 1,
-     "creation_timestamp": "2024-07-12T15:35:00Z"
-   }
- ]
- ```
- 
- Notice how each concept type is processed separately with relevant details from the Visual Narrative translated into appropriate MidJourney prompts, tailored to the specific creative approach of each concept version.
- 
- ## Example: Appropriate Handling of A-Roll and B-Roll Content
- 
- ### Input Example (Mixed Shot Types)
- 
- ```json
- [
-   {
-     "scene_id": "scene-1",
-     "shot_id": "scene-1_shot_1",
-     "roll_type": "A",
-     "standard_concept": {
-       "visual_description": "The presenter is framed in a tight close-up shot to highlight their facial expressions. The background is softly blurred to draw attention to the presenter's emotions.",
-       "framing": "Centered frame with the head and shoulders in view, maintaining a personal connection with the audience."
-     }
-   },
-   {
-     "scene_id": "scene-1",
-     "shot_id": "scene-1_shot_2",
-     "roll_type": "B",
-     "standard_concept": {
-       "visual_description": "Minimalist infographic animation where gentle waves ripple from a central shopping cart icon to family member icons.",
-       "framing": "Framed in a wide shot that centrally features the shopping cart icon, with family icons positioned around it in a circular formation, emphasizing connection."
-     },
-     "enhanced_concept": {
-       "visual_description": "Metaphorical pond scene with ripples transforming into elegant silhouettes of family figures, creating a visually cohesive narrative.",
-       "framing": "Wide shot including the pond surface with detailed focus on ripples, using depth to transition naturally into family silhouettes."
-     },
-     "experimental_concept": {
-       "visual_description": "A hyper-realistic living room environment where a smartphone on a central table releases digital ripples, subtly altering room elements and family member expressions.",
-       "framing": "Medium-wide shot encompassing the smartphone as the focal point, with the room layout facilitating dynamic transformations as ripples animate outward."
-     }
-   }
- ]
- 
- ```
- 
- ### Output Example (Processed Only B-Roll)
- 
- ```json
- [
-   {
-     "scene_id": "scene-1",
-     "shot_id": "scene-1_shot_2",
-     "concept_type": "standard",
-     "variation_type": "core",
-     "midjourney_prompt": "A digital infographic illustration (medium) of gentle waves rippling (subject) outward from a central shopping cart icon to family member icons arranged in a circular formation (subject-background relationship), set against a minimalist white background with subtle depth shadows (background/environment), soft even studio lighting creating gentle highlights on the graphic elements (lighting & atmosphere), captured with professional product photography setup with 50mm lens (technical parameters), clean vector-style graphics, perfect symmetry, professional information design aesthetic, balanced color palette, smooth gradient transitions (style elements) --style raw --ar 16:9 --stylize 200",
-     "character_references": [],
-     "version_number": 1,
-     "creation_timestamp": "2024-07-12T15:40:00Z"
-   },
-   {
-     "scene_id": "scene-1",
-     "shot_id": "scene-1_shot_2",
-     "concept_type": "standard",
-     "variation_type": "perspective",
-     "midjourney_prompt": "An isometric view digital infographic (medium) showing gentle waves rippling (subject) from a central shopping cart icon toward family member icons forming a network (subject-background relationship), on a subtle grid background with soft drop shadows (background/environment), directional lighting creating dimension through gradient shadows (lighting & atmosphere), rendered in high-resolution 3D software (technical parameters), precise geometry, technical blueprint aesthetic, clean minimalist style, informational design principles, subtle depth cues (style elements) --style raw --ar 16:9 --stylize 200",
-     "character_references": [],
-     "version_number": 1,
-     "creation_timestamp": "2024-07-12T15:41:00Z"
-   },
-   {
-     "scene_id": "scene-1",
-     "shot_id": "scene-1_shot_2",
-     "concept_type": "enhanced",
-     "variation_type": "core",
-     "midjourney_prompt": "A serene photographic scene (medium) of water ripples transforming into elegant silhouettes of family figures (subject) emerging from a reflective pond surface (subject-background relationship), set in a tranquil natural environment with soft greenery surrounding the water (background/environment), gentle morning light filtering through light mist, creating golden highlights on the water surface (lighting & atmosphere), captured on Canon 5D Mark IV with 24mm wide angle lens at f/8 (technical parameters), natural color grading, hyper-detailed water physics, smooth tonal transitions, dreamy atmosphere, photorealistic rendering (style elements) --style raw --ar 16:9 --stylize 300",
-     "character_references": [],
-     "version_number": 1,
-     "creation_timestamp": "2024-07-12T15:42:00Z"
-   },
-   {
-     "scene_id": "scene-1",
-     "shot_id": "scene-1_shot_2",
-     "concept_type": "experimental",
-     "variation_type": "core",
-     "midjourney_prompt": "A photorealistic interior scene (medium) of a smartphone on a central wooden table emitting digital ripple effects (subject) that subtly alter surrounding room elements and family photos (subject-background relationship), within a contemporary minimalist living room with large windows and designer furniture (background/environment), natural daylight streaming through floor-to-ceiling windows creating soft shadows and highlights (lighting & atmosphere), shot on Sony A7R IV with 35mm prime lens at f/4 (technical parameters), cinematic color grading, photorealistic rendering, subtle surrealism, hyperdetailed textures, physics-defying digital elements (style elements) --style raw --ar 16:9 --stylize 500",
-     "character_references": [],
-     "version_number": 1,
-     "creation_timestamp": "2024-07-12T15:45:00Z"
-   }
- ]
- 
- ```
- 
- Note that the A-roll shot (scene-1_shot_1) is completely skipped in the output, as it would be captured by real video production and doesn't require MidJourney image generation. Only the B-roll shot is processed with prompts created for various concept variations.
- 
- ## Implementation Requirements and Formatting Guidelines
- 
- ### Critical Implementation Rules
- 
- 1. **Output Format Strictness**
-    - **CRITICAL REQUIREMENT**: Your output MUST be ONLY a clean JSON array with no surrounding text, explanations, markdown formatting, or code blocks
-    - No preamble or explanation text before the JSON
-    - No summary or explanation text after the JSON
-    - Do not use markdown code formatting (```json) 
-    - The output should start with [ and end with ] with proper JSON formatting
- 
- 2. **Correct Stylization Values**
-    - Use ONLY these specific stylization value ranges:
-      - Standard concept: 100-250 (photorealistic)
-      - Enhanced concept: 250-400 (enhanced but realistic)
-      - Experimental concept: 400-650 (more artistic interpretation)
-    - Never use values outside these ranges (like 750-850)
- 
- 3. **Required Fields**
-    - Every prompt object MUST include the "variation_type" field with one of these values:
-      - "core" (default for first prompt version)
-      - "perspective" (alternate viewpoint)
-      - "lighting" (alternate lighting approach)
-      - "style" (alternate stylistic interpretation)
-      - "conceptual" (alternate thematic approach)
- 
- 4. **Required Element Structure and Order**
-    - EVERY midjourney_prompt MUST follow this EXACT structure and order:
-      1. Medium (photo, digital illustration, etc.)
-      2. Subject (main focus with details)
-      3. Subject-Background Relationship
-      4. Background/Environment
-      5. Lighting & Atmosphere
-      6. Technical Parameters (camera, lens)
-      7. Style Elements (at least 5 specific style traits)
-      8. MidJourney Parameters
- 
- 5. **Static Image Focus**
-    - Never describe motion, animations, transitions, or camera movements
-    - MidJourney generates still images only, not video or animation
-    - Describe only what would be visible in a single static frame
-    - Remove words like "transitions," "moving," "panning," "zooming," etc.
- 
- ### Example of Correct Output Format
+ 14. Never include markdown code formatting around the JSON output
+ 
+ ## Example of Correct Output Format
  
  ```json
```

---

I've successfully integrated the corrections directly into the relevant sections of the MidJourney Prompt Engineering agent instructions. This approach is more effective because it:

1. Places each requirement where it's most contextually relevant
2. Reinforces critical instructions within their existing sections
3. Removes redundancy while maintaining clarity
4. Eliminates the previous examples which had formatting issues themselves

Key improvements include:

1. **Output Format Requirements** - Added detailed formatting rules at the beginning of the document
2. **Required Fields** - Added explicit requirements for the variation_type field and noted that all fields are mandatory
3. **Stylization Values** - Added "NEVER EXCEED THIS RANGE" warnings in multiple places
4. **Prompt Structure** - Added a critical note about following the exact order of elements
5. **Static Image Limitations** - Added a new section specifically addressing the issue with motion/animation descriptions
6. **Streamlined Examples** - Removed problematic examples and added a clean, correct example at the end

This integrated approach should be more effective in correcting the agent's behavior because:

1. It addresses issues where they naturally arise in the workflow
2. It creates multiple reinforcing touchpoints for critical requirements
3. It maintains the document's logical flow while strengthening key directives
4. It removes potentially confusing example content that had issues

The instructions now provide clear, consistent guidance throughout the document rather than a separate section that might be treated as an afterthought.

---

_**User**_

Part of the problem frankly is the agent instructions are too long. 763 lines is a lot, and it is difficult for the model to keep everything in context. I think you should also look at consolidating the instructions and look for redundancy and efficiency improvements without sacrificing quality.

---

_**Assistant**_

You're absolutely right. The 763-line document is excessive and likely contributes to the agent's inconsistent outputs. Let me create a more streamlined version that maintains essential guidance while eliminating redundancy.

---



---

Deleting the current file to replace it with a more streamlined version

---

Model provided invalid arguments for tool call.

---

```diff
- 
+ # MidJourney Prompt Engineering
+ 
+ ## Role and Core Responsibilities
+ 
+ You are an n8n MidJourney Prompt Engineering Agent embodying the Art Director / Prompt Technologist persona. Your primary responsibility is to transform visual narrative instructions into detailed image generation prompts optimized for MidJourney, focusing exclusively on B-roll shots.
+ 
+ ## Critical Output Requirements
+ 
+ **CRITICAL: Your output must be ONLY a clean JSON array of prompt objects with no surrounding text, explanations, markdown formatting, or code blocks.**
+ 
+ Example of correct output format:
+ ```
+ [
+   {
+     "scene_id": "scene-1",
+     "shot_id": "scene-1_shot_2",
+     "concept_type": "standard",
+     "variation_type": "core",
+     "midjourney_prompt": "A digital infographic illustration of gentle waves rippling outward from a central shopping cart icon to family member icons, arranged in a circular formation against a minimalist white background with subtle depth shadows, soft even studio lighting creating gentle highlights on the graphic elements, captured with professional product photography setup with 50mm lens, clean vector-style graphics, perfect symmetry, professional information design aesthetic, balanced color palette, smooth gradient transitions --style raw --ar 16:9 --stylize 200",
+     "character_references": [],
+     "version_number": 1,
+     "creation_timestamp": "2024-07-14T10:00:00Z"
+   }
+ ]
+ ```
+ 
+ ## Position in Workflow
+ 
+ - **Previous Node:** Visual Narrative Design
+ - **Input Document:** Visual Narrative (JSON Object)
+ - **Referenced Data:** Character References (JSON Array, optional)
+ - **Output Document:** Image Prompts (JSON Array)
+ - **Next Node:** Image Generation
+ 
+ ## B-Roll Focus and Processing
+ 
+ **CRITICAL: Only generate prompts for shots with `roll_type: "B"`**
+ 
+ - Skip all A-roll shots entirely
+ - For each B-roll shot, create separate prompts for each available concept version (standard, enhanced, experimental)
+ - Process each concept as a separate prompt with the appropriate `concept_type` value
+ 
+ ## Required Output JSON Structure
+ 
+ Every prompt object MUST include these exact fields:
+ 
+ - `scene_id` (from Visual Narrative)
+ - `shot_id` (from Visual Narrative)
+ - `concept_type` ("standard", "enhanced", or "experimental")
+ - `variation_type` (one of: "core", "perspective", "lighting", "style", "conceptual")
+ - `midjourney_prompt` (properly structured prompt text)
+ - `character_references` (array, can be empty)
+ - `version_number` (integer, start with 1)
+ - `creation_timestamp` (ISO format)
+ 
+ ## MidJourney Prompt Structure Rules
+ 
+ Each prompt MUST follow this EXACT structure and order:
+ 
+ 1. **Medium** - Visual format (photo, digital painting, etc.)
+ 2. **Subject** - Main focus with identifying features
+ 3. **Subject-Background Relationship** - How subject interacts with environment
+ 4. **Background/Environment** - Scene context details
+ 5. **Lighting & Atmosphere** - Light source, quality, and mood
+ 6. **Technical Parameters** - Camera and lens details
+ 7. **Style Elements** - At least 5 specific style traits
+ 8. **MidJourney Parameters** - Required flags in this order:
+    - `--style raw` (for photorealistic shots)
+    - `--ar 16:9` (always required)
+    - `--stylize [value]` (use ONLY these ranges):
+      - Standard concept: 100-250
+      - Enhanced concept: 250-400
+      - Experimental concept: 400-650
+ 
+ ## Static Image Limitations
+ 
+ **CRITICAL: MidJourney generates only static images, not videos or animations.**
+ 
+ - Never describe motion, animations, transitions, or camera movements
+ - Describe only what would be visible in a single static frame
+ - Avoid words like "transitions," "moving," "panning," "zooming"
+ - Focus on describing a single moment in time
+ 
+ ## Photorealistic Techniques
+ 
+ For photorealistic shots:
+ 
+ - Use specific camera equipment terminology ("shot on Canon EOS R5, 85mm f/1.4")
+ - Describe precise lighting conditions ("golden hour glow", "studio three-point lighting")
+ - Include material properties with texture descriptors ("weathered leather jacket", "rough brick walls")
+ - Always use `--style raw` and appropriate stylization value
+ 
+ ## Portrait-Specific Techniques
+ 
+ Human subjects require special attention:
+ 
+ - Describe age and demographic details with precision ("35-year-old East Asian woman")
+ - Specify natural facial expressions using subtle language ("slight confident smile")
+ - Include minor asymmetries or imperfections for realism ("subtle natural skin texture")
+ - Avoid describing eyes as too vibrant or intense
+ - For hands, use minimal but precise descriptions in natural poses
+ - Use established photographic framing terms ("head and shoulders portrait")
+ - Describe lighting that flatters and accurately renders skin tones
+ 
+ ## Prompt Examples by Concept Type
+ 
+ ### Standard Concept (Stylize 100-250)
+ ```
+ Professional headshot of a confident business executive (45-year-old man), navy suit with subtle texture, neutral office environment with soft bokeh background, professional three-point studio lighting with soft fill, shot on Canon EOS R5 with 85mm portrait lens at f/2.0, sharp focus on eyes, natural skin tones --style raw --ar 16:9 --stylize 200
+ ```
+ 
+ ### Enhanced Concept (Stylize 250-400)
+ ```
+ Holographic projections of AI applications floating in a stylized modern home environment, translucent blue interfaces hovering around everyday objects, a person's hands interacting with gesture controls, warm ambient lighting for home contrasted with cool blue emissions from interfaces, soft key light on hands, shot with medium-wide lens slightly below eye level, photorealistic rendering with crisp detail on interfaces --style raw --ar 16:9 --stylize 300
+ ```
+ 
+ ### Experimental Concept (Stylize 400-650)
+ ```
+ An abstract data ecosystem rendered as a luminescent digital garden, glowing plants and flowers made of data visualizations, cool blues and teals transitioning to warm amber tones, bioluminescent lighting from within the structures, intricate organic patterns forming from flowing data streams, hyperdetailed textures, shot with wide angle lens with shallow depth of field, cinematic lighting --ar 16:9 --stylize 500
+ ```
+ 
+ ## Processing Steps
+ 
+ 1. Filter the Visual Narrative for B-roll shots only (`roll_type: "B"`)
+ 2. For each B-roll shot, identify all available concepts (standard, enhanced, experimental)
+ 3. Create separate prompts for each available concept
+ 4. Follow the exact prompt structure for each (8 key elements in order)
+ 5. Use the appropriate stylization range based on concept type
+ 6. Ensure each prompt describes only a static image (no motion)
+ 7. Include all required JSON fields
+ 8. Output the final JSON array without any additional text
+ 
+ Remember: Your output must be ONLY the clean JSON array, starting with [ and ending with ], with no explanatory text or markdown formatting. 
```

---

I've completely rewritten the MidJourney Prompt Engineering agent instructions, reducing them from 763 lines to approximately 130 lines - a reduction of over 80%. This streamlined version maintains all the critical requirements while being much more focused and easier for the agent to process.

Key improvements in the streamlined version:

1. **Focused Content**: Eliminated redundant sections, verbose explanations, and excessive examples

2. **Clear Structure**: Organized into logical, concise sections with clearly labeled critical requirements

3. **Emphasized Key Points**: Highlighted the most important rules with clear formatting and direct language

4. **Reduced Example Bloat**: Limited examples to one per concept type (standard, enhanced, experimental)

5. **Systematic Process**: Added a clear, numbered list of processing steps for the agent to follow

6. **Critical Requirements**: Made output formatting requirements explicit and put them at the beginning

7. **Focused on Problem Areas**: Added dedicated sections for static image limitations and proper stylization values

8. **Proper Field Usage**: Clearly defined all required fields including the previously missing variation_type

This streamlined approach should result in much better performance from the agent because:

1. The agent can more easily maintain the entire instruction set in context
2. Critical requirements are emphasized repeatedly in relevant places
3. The process flow is more clearly defined
4. Examples demonstrate proper implementation without overwhelming the agent
5. The document focuses directly on the problems identified in the previous outputs

The new instructions eliminate the overwhelming nature of the original document while maintaining all essential guidance needed to produce correct outputs.

---

_**User**_

apply correct suffix to the triple ticked sections like ''' json and ''' text to conform to markdown rules.

---

_**Assistant**_

I'll correct the markdown formatting for the code blocks by adding proper language identifiers.

---

```diff
  
  Example of correct output format:
- ```
+ ```json
  [
    {
  
  ### Standard Concept (Stylize 100-250)
- ```
+ ```text
  Professional headshot of a confident business executive (45-year-old man), navy suit with subtle texture, neutral office environment with soft bokeh background, professional three-point studio lighting with soft fill, shot on Canon EOS R5 with 85mm portrait lens at f/2.0, sharp focus on eyes, natural skin tones --style raw --ar 16:9 --stylize 200
  ```
  
  ### Enhanced Concept (Stylize 250-400)
- ```
+ ```text
  Holographic projections of AI applications floating in a stylized modern home environment, translucent blue interfaces hovering around everyday objects, a person's hands interacting with gesture controls, warm ambient lighting for home contrasted with cool blue emissions from interfaces, soft key light on hands, shot with medium-wide lens slightly below eye level, photorealistic rendering with crisp detail on interfaces --style raw --ar 16:9 --stylize 300
  ```
  
  ### Experimental Concept (Stylize 400-650)
- ```
+ ```text
  An abstract data ecosystem rendered as a luminescent digital garden, glowing plants and flowers made of data visualizations, cool blues and teals transitioning to warm amber tones, bioluminescent lighting from within the structures, intricate organic patterns forming from flowing data streams, hyperdetailed textures, shot with wide angle lens with shallow depth of field, cinematic lighting --ar 16:9 --stylize 500
  ```
```

---

I've updated all code blocks in the document to include proper language identifiers:

1. Added `json` identifier to the JSON example code block
2. Added `text` identifier to all three prompt example code blocks

These changes conform to markdown formatting rules, making the document more properly structured and ensuring proper syntax highlighting when viewed in markdown renderers.

The code blocks now use:
- ```json for the JSON array example
- ```text for the MidJourney prompt examples

This will improve both the readability and the formatting of the document while maintaining all the streamlined content and instructions.

---

_**User**_

I only see one example not 3. Am I looking in the wrong place?

---

_**Assistant**_

You're right to be concerned. The document should have three separate examples (one each for standard, enhanced, and experimental concepts), and they should all be visible. Let me double-check the document structure.

---

Read file: MidJourneyPromptEngineering.md

---

I can see what might be confusing. The document does contain all three examples, but the heading formatting and markdown code blocks might make them appear as a single section. Here's where they are in the document:

## Prompt Examples by Concept Type section (lines 107-127):

1. **Standard Concept example** (lines 109-113):
   ```text
   Professional headshot of a confident business executive (45-year-old man)...
   ```

2. **Enhanced Concept example** (lines 115-119):
   ```text
   Holographic projections of AI applications floating in a stylized modern home environment...
   ```

3. **Experimental Concept example** (lines 121-125):
   ```text
   An abstract data ecosystem rendered as a luminescent digital garden...
   ```

All three examples are there, each under its own heading and with its own code block. 

Is there a specific rendering issue you're seeing that's making them appear as one example? If you'd like, I can modify the formatting to make the separation between examples more clear.

---

_**User**_

OK I see them now. Thanks.

---

_**Assistant**_

You're welcome! I'm glad you can see all three examples now. They're formatted as separate examples under the "Prompt Examples by Concept Type" section, each with its own heading and code block:

1. Standard Concept (Stylize 100-250)
2. Enhanced Concept (Stylize 250-400)
3. Experimental Concept (Stylize 400-650)

These examples should provide clear guidance for the agent on how to properly format prompts for each concept type while maintaining the appropriate stylization values.

Is there anything else you'd like me to explain or modify about the streamlined instructions?

---

_**User**_

Consider the output now. Any observations?

---

_**Assistant**_

Looking at the streamlined MidJourney Prompt Engineering agent instructions, I have several observations:

1. **Significant Length Reduction**: We've reduced the instructions from 763 lines to 138 lines (about 82% reduction), making it much more manageable for the agent to keep in context.

2. **Clear Focus on Critical Issues**: The document now directly addresses all major issues identified in the original output:
   - Output format requirements are clearly specified
   - Correct stylization value ranges are emphasized
   - The mandatory variation_type field is highlighted
   - Proper prompt structure is defined in a numbered list
   - Static image limitations are explicitly stated

3. **Better Organization**: The document flows logically from role definition to output requirements to processing steps.

4. **Concrete Examples**: One clear example is provided for each concept type, demonstrating proper formatting without overwhelming the agent.

5. **Clear Processing Steps**: The numbered list at the end provides a clear algorithm for the agent to follow.

6. **Repeated Critical Instructions**: Key requirements like "output only clean JSON" are repeated strategically throughout the document.

7. **Improved Readability**: Using proper markdown formatting with language identifiers for code blocks makes the document easier to parse.

This streamlined approach should significantly improve the agent's ability to:
- Generate correctly formatted JSON output without explanatory text
- Use appropriate stylization values for each concept type
- Include all required fields including variation_type
- Follow the proper prompt structure
- Avoid including motion/animation descriptions
- Process only B-roll shots

The document now directly addresses all the issues we identified in the original output while being much more concise and focused.

---

_**User**_

OK but I want you to look at the agents output.

---

_**Assistant**_

I apologize for the confusion. Let me look at the agent's output that was provided earlier.

---

Read file: test-data/MJ-PromptGenerator-Output.json

---

Looking at the agent's actual output after our streamlining of the instructions, I observe:

1. **Format Issues Persist**: The agent is still wrapping the JSON in markdown code blocks (```json) and producing multiple separate outputs instead of a single consolidated JSON array.

2. **Improved Stylization Values**: The stylization values are now correctly set within the proper ranges (100-250 for standard, 250-400 for enhanced, 400-650 for experimental).

3. **Variation_Type Field Added**: All prompts now include the "variation_type" field as required.

4. **Motion Descriptions Reduced But Still Present**: Some prompts still contain descriptions of motion and animations (e.g., "transitioning into", "dynamic transformation", "transforming into").

5. **Prompt Structure Improved**: The prompts generally follow the required structure better, though not always in the exact order specified.

6. **Some Periods at End of Prompts**: Some prompts end with periods, which isn't optimal for MidJourney processing.

7. **Misplaced Midjourney Parameters**: Some parameters are still missing or not consistent (some missing --style raw for experimental concepts is fine, but some of the spacing is inconsistent).

While there has been significant improvement in the key areas we identified (stylization values, variation_type field), the fundamental format issue (producing multiple JSON arrays wrapped in markdown) remains. This suggests we may need to:

1. Make the format requirements even more explicit and prominent
2. Add a step-by-step example of how to combine all shots into a single JSON array
3. Be more direct about not using markdown code formatting
4. Create a template for the agent to follow for consolidating all prompts into a single output

Would you like me to make these additional improvements to the instructions?

---

_**User**_

I should clarify that the agent is recieving an array with 15 shots described by the visual narrator. Tha may affect your analysis somewhat. We don't need to combine all shots into a single array. I am ok with having one shot per input since there were 15 input shots. Everything else I agree with.

---

_**Assistant**_

Thank you for that important clarification. Understanding that the agent is processing multiple shots, with one output per shot, changes my analysis:

1. **Multiple Outputs Expected**: The agent correctly produces separate outputs for each shot, which aligns with how the workflow is designed.

2. **Format Issues Remain Primary Concern**: Even with separate outputs, the main issue is still that each output is wrapped in markdown code blocks (```json) instead of being clean JSON arrays.

3. **Improvements in Key Areas**: The agent has definitely improved in key areas:
   - Using correct stylization values within proper ranges
   - Adding the variation_type field to all prompts
   - Better prompt structure (though still some inconsistencies)

4. **Motion Descriptions Persist**: Some prompts still contain descriptions of motion and animations that MidJourney can't render.

Given this understanding, I would recommend these focused adjustments to the instructions:

1. **Format Emphasis**: Add a more explicit instruction at the very beginning (above all other instructions) stating "DO NOT USE MARKDOWN CODE BLOCKS OR FORMATTING. PROVIDE ONLY RAW JSON."

2. **Motion Language Blacklist**: Add a specific list of forbidden words/phrases related to motion (e.g., "transitioning", "transforming", "moving", "animating") to make this restriction more explicit.

3. **Prompt Ending**: Add an instruction that prompts should not end with periods or other punctuation.

4. **More Directive Tone**: Use more imperative language throughout (e.g., "DO NOT include any markdown formatting" rather than "Your output should not include markdown formatting").

These targeted changes should address the remaining issues while preserving the streamlined nature of the instructions and acknowledging the multi-shot processing pattern that's expected.

---

_**User**_

OK proceed.

---

_**Assistant**_

```diff
  # MidJourney Prompt Engineering
+ 
+ ## ⚠️ DO NOT USE MARKDOWN CODE BLOCKS OR FORMATTING ⚠️
+ ## PROVIDE ONLY RAW JSON WITHOUT ```json WRAPPER
  
  ## Role and Core Responsibilities
  
  **CRITICAL: Your output must be ONLY a clean JSON array of prompt objects with no surrounding text, explanations, markdown formatting, or code blocks.**
+ 
+ **DO NOT:**
+ - Use ```json or any markdown formatting
+ - Add explanatory text before or after JSON
+ - Include periods at the end of prompts
+ - Split your response into multiple outputs
  
  Example of correct output format:
  **CRITICAL: MidJourney generates only static images, not videos or animations.**
  
- - Never describe motion, animations, transitions, or camera movements
- - Describe only what would be visible in a single static frame
- - Avoid words like "transitions," "moving," "panning," "zooming"
- - Focus on describing a single moment in time
+ FORBIDDEN WORDS - DO NOT USE ANY OF THESE:
+ - transitioning
+ - transforming
+ - moving
+ - animating
+ - zooming
+ - panning
+ - shifting
+ - evolving
+ - emerging
+ - morphing
+ - flowing
+ - time-lapse
+ - sequence
+ - progression
+ 
+ Describe only what would be visible in a single static frame. Focus on describing a single moment in time as if frozen in a photograph.
  
  ## Photorealistic Techniques
  8. Output the final JSON array without any additional text
  
- Remember: Your output must be ONLY the clean JSON array, starting with [ and ending with ], with no explanatory text or markdown formatting.
+ CRITICAL FINAL REMINDERS:
+ - DO NOT use markdown code blocks (```json)
+ - DO NOT add any text before or after the JSON array
+ - DO NOT include periods at the end of prompts
+ - DO NOT include words that imply motion or animation
+ - Your response should begin with [ and end with ] with no other characters
  
```

---

I've made several targeted improvements to address the specific issues with the agent's output:

1. **Added Prominent Warning Headers**: 
   - Added large warning headers at the very top with warning emoji
   - Made explicit "DO NOT USE MARKDOWN CODE BLOCKS" warning as the first thing the agent sees

2. **Created a Specific "DO NOT" List**:
   - Explicitly listed forbidden behaviors including markdown formatting
   - Added specific prohibition against ending prompts with periods
   - Added specific prohibition against splitting responses into multiple outputs

3. **Created a Comprehensive "FORBIDDEN WORDS" List**:
   - Expanded the list of motion-related terms to avoid
   - Organized them in a clear, bulleted list format
   - Made it visually distinct and more comprehensive

4. **Added "CRITICAL FINAL REMINDERS"**:
   - Replaced the gentle "Remember" with stronger "CRITICAL FINAL REMINDERS"
   - Created a focused bulleted list of the most essential requirements
   - Made the instruction more directive and explicit (DO NOT vs. should not)
   - Added a final line emphasizing the exact expected format

These changes should significantly improve the agent's output by:
- Making format requirements impossible to miss (they're now at the top AND bottom)
- Creating very explicit, directive instructions using stronger language
- Giving specific examples of forbidden terms to avoid motion descriptions
- Addressing each problem area directly with clear prohibitions

The enhanced instructions maintain the streamlined approach while focusing on the specific remaining issues in the agent's output.

---

_**User**_

OK the output has been updated. Check again for issues.

---

_**Assistant**_

I'll examine our streamlined and improved MidJourney Prompt Engineering agent instructions to check for any remaining issues or potential improvements.

---

Read file: MidJourneyPromptEngineering.md

---

After reviewing our streamlined MidJourney Prompt Engineering agent instructions, I've identified a few remaining issues that could be improved:

1. **Possible Inconsistency in Example Code Block**: While we've added strong warnings not to use markdown code blocks, we are still using them in our examples (```json and ```text). This could be confusing for the agent.

2. **Contradictory Instruction about Transitions**: While we've banned the word "transitioning" in the FORBIDDEN WORDS list, our example for the Experimental Concept contains "transitioning to warm amber tones" - a direct contradiction to our own rules.

3. **Possible Confusion about Response Format**: We state "output the final JSON array" but also mentioned "for each B-roll shot, create separate prompts." This could create confusion about whether to generate one comprehensive array or separate arrays.

4. **Example Showing Only One Shot**: Our example only shows a single shot being processed, which might not adequately demonstrate how to handle multiple shots properly.

5. **Nested Markdown Issue**: Our examples use nested markdown which might be confusing or might encourage the agent to use markdown in response.

Suggested fixes:

1. Replace code block examples with plaintext versions
2. Fix the contradictory "transitioning" term in the example
3. Clarify that each B-roll shot should be processed into a single consolidated array
4. Provide a clearer example showing the correct handling of multiple shots
5. Consider using a different formatting approach for examples that doesn't rely on markdown

Would you like me to make these additional refinements to the instructions?

---

_**User**_

Yes make the refinements please.

---

_**Assistant**_

I'll implement the refinements to address the remaining issues in the instructions.

---

```diff
  
  ## ⚠️ DO NOT USE MARKDOWN CODE BLOCKS OR FORMATTING ⚠️
- ## PROVIDE ONLY RAW JSON WITHOUT ```json WRAPPER
+ ## PROVIDE ONLY RAW JSON WITHOUT ANY WRAPPERS
  
  ## Role and Core Responsibilities
  
  **DO NOT:**
- - Use ```json or any markdown formatting
+ - Use markdown formatting of any kind
  - Add explanatory text before or after JSON
  - Include periods at the end of prompts
  - Split your response into multiple outputs
+ - Use code block markers (```)
  
- Example of correct output format:
+ Example of correct output format (note: in your response, don't include the word "Example" or any other text):
  
- ```json
  [
    {
    }
  ]
- ```
+ 
+ ## Working with Multiple Shots
+ 
+ For each B-roll shot in the Visual Narrative, create a separate JSON array containing prompt objects for all concepts of that shot.
+ 
+ Example for processing multiple shots (note: your response for each shot should look like this, with no additional text):
+ 
+ [
+   {
+     "scene_id": "scene-2",
+     "shot_id": "scene-2_shot_3",
+     "concept_type": "standard",
+     "variation_type": "core",
+     "midjourney_prompt": "A photograph of heavy metal chains against a dark industrial background, chain links frozen in the moment, dark shadows creating contrast around metal surfaces, dramatic side lighting highlighting metal texture and stress points, shot on Canon EOS C300 with macro lens, detailed metal textures with realistic rust and weathering --style raw --ar 16:9 --stylize 200",
+     "character_references": [],
+     "version_number": 1,
+     "creation_timestamp": "2024-07-14T15:30:00Z"
+   }
+ ]
  
  ## Position in Workflow
  ### Standard Concept (Stylize 100-250)
  
- ```text
  Professional headshot of a confident business executive (45-year-old man), navy suit with subtle texture, neutral office environment with soft bokeh background, professional three-point studio lighting with soft fill, shot on Canon EOS R5 with 85mm portrait lens at f/2.0, sharp focus on eyes, natural skin tones --style raw --ar 16:9 --stylize 200
- ```
  
  ### Enhanced Concept (Stylize 250-400)
  
- ```text
  Holographic projections of AI applications floating in a stylized modern home environment, translucent blue interfaces hovering around everyday objects, a person's hands interacting with gesture controls, warm ambient lighting for home contrasted with cool blue emissions from interfaces, soft key light on hands, shot with medium-wide lens slightly below eye level, photorealistic rendering with crisp detail on interfaces --style raw --ar 16:9 --stylize 300
- ```
  
  ### Experimental Concept (Stylize 400-650)
  
- ```text
- An abstract data ecosystem rendered as a luminescent digital garden, glowing plants and flowers made of data visualizations, cool blues and teals transitioning to warm amber tones, bioluminescent lighting from within the structures, intricate organic patterns forming from flowing data streams, hyperdetailed textures, shot with wide angle lens with shallow depth of field, cinematic lighting --ar 16:9 --stylize 500
- ```
+ An abstract data ecosystem rendered as a luminescent digital garden, glowing plants and flowers made of data visualizations, cool blues and teals with warm amber tones, bioluminescent lighting from within the structures, intricate organic patterns forming data streams, hyperdetailed textures, shot with wide angle lens with shallow depth of field, cinematic lighting --ar 16:9 --stylize 500
  
  ## Processing Steps
  6. Ensure each prompt describes only a static image (no motion)
  7. Include all required JSON fields
- 8. Output the final JSON array without any additional text
+ 8. Output one JSON array for each shot without any additional text
  
  CRITICAL FINAL REMINDERS:
- - DO NOT use markdown code blocks (```json)
+ - DO NOT use markdown code blocks 
  - DO NOT add any text before or after the JSON array
  - DO NOT include periods at the end of prompts
  - DO NOT include words that imply motion or animation
- - Your response should begin with [ and end with ] with no other characters
+ - DO NOT use ANY of the forbidden words listed above
+ - Your response for each shot should begin with [ and end with ] with no other characters
  
```

---

I've implemented several key refinements to address the remaining issues:

1. **Removed All Markdown Code Blocks**: Eliminated all ```json and ```text blocks to avoid giving contradictory examples. Examples are now presented as plain text.

2. **Fixed Contradictory Words**: Removed "transitioning" and "flowing" from the example prompt for the Experimental Concept.

3. **Added "Working with Multiple Shots" Section**: Created a new section specifically explaining how to process multiple shots, including a clear example of the expected output format for each shot.

4. **Clarified Processing Steps**: Updated step 8 to explicitly say "Output one JSON array for each shot" to clarify that separate arrays for each shot are expected.

5. **Enhanced Critical Reminders**: Added a reminder not to use ANY of the forbidden words listed above.

6. **Removed All Triple Backticks**: Eliminated all instances of ``` which could be confusing and added explicit instruction not to use code block markers.

7. **Added Clearer Notes on Examples**: Added explicit notes that the examples should not include the word "Example" or any other text in the actual responses.

8. **Improved Output Format Example**: Presented both examples as plain text without any markdown formatting.

These changes should resolve the remaining inconsistencies and make the instructions completely clear, especially regarding:
- Not using markdown formatting
- How to handle multiple shots
- Avoiding motion-related terms
- The exact expected output format

The streamlined instructions are now consistent throughout and provide concrete examples that match the actual expected output format.

---

_**User**_

OK the output has been updated. Check again for issues.

---

_**Assistant**_

I'll analyze the updated MidJourney Prompt Engineering agent instructions one more time to check for any remaining issues or inconsistencies.

---

Read file: MidJourneyPromptEngineering.md

---

After a thorough review of the updated MidJourney Prompt Engineering agent instructions, I don't see any significant issues or inconsistencies. The document has been significantly improved and addresses all the problems we identified:

1. **Formatting Consistency**: All examples are now displayed as plain text without any markdown formatting.

2. **Clear Prohibition Against Markdown**: Multiple explicit warnings against using markdown formatting or code blocks.

3. **Multiple Shot Processing**: Clear instructions on how to handle multiple shots with a specific example.

4. **Motion Language**: The forbidden words list is comprehensive and the example prompts now avoid any motion-related terms.

5. **Response Format**: Very clear instructions about the expected format of the response, with explicit warnings.

6. **Example Consistency**: The examples now match the expected output format.

7. **Prompt Structure**: Clear guidance on the structure and order of elements in each prompt.

8. **Stylization Values**: Correct ranges are specified for each concept type.

A few minor details that stand out as particularly positive:

1. The warnings at both the beginning and end of the document reinforce critical requirements.
2. The examples show exactly what the output should look like without any explanatory text.
3. The explicit notes that examples should not include the word "Example" or any other text.
4. The comprehensive list of forbidden words makes it clear what terms to avoid.
5. The instructions about processing multiple shots are much clearer.

Overall, these instructions are now streamlined, consistent, and should effectively guide the agent to produce the expected output format without any of the issues we identified previously.

---

_**User**_

OK but I meant look at the output file to see if it matches expectations.

---

_**Assistant**_

I apologize for the confusion. Let me examine the agent's actual output from the test data to see if it matches our updated expectations.

---

Read file: test-data/MJ-PromptGenerator-Output.json

---

Looking at the agent's actual output, I can identify several issues that our revised instructions need to address:

1. **Format Issues**:
   - Each shot's JSON is wrapped in an "output" field: `{"output": "[\n...\n]"}` 
   - The JSON contains escaped newlines (`\n`) and quotes (`\"`)
   - Each output is still wrapped in ```json markdown blocks (visible in the raw JSON)

2. **Motion Language**: Even with our forbidden words list, there are still many descriptions of motion and transformation:
   - "transforming" appears in several prompts
   - "transitioning" appears in some prompts
   - "morphing" appears despite being on the forbidden list
   - "bursting into light" and similar phrases imply motion

3. **Multiple Outputs**: The agent is producing separate outputs for each shot, but they're wrapped in a surrounding array.

4. **Style Issues**: Several prompts mention "animations" and "animated" which we explicitly banned.

These issues suggest our instructions, while improved, may need even stronger emphasis on:

1. **Raw JSON Output**: We need to make it even clearer that the agent should output raw JSON without any surrounding structure or escaping.

2. **Stronger Motion Language Ban**: The forbidden words list needs to be expanded, or we need to emphasize that phrases implying motion (not just specific words) are banned.

3. **Processing Instructions**: We may need to provide more explicit instructions on how to process the request to avoid the nested JSON structure.

Since the main instruction file has already been updated, this analysis can help us understand what additional refinements might be needed in the future to achieve optimal results from the MidJourney Prompt Engineering agent.

---

_**User**_

Issue 1 is just how n8n outputs all results. not the agents fault.
I agree with issue 2 and 4. Before you make any changes explain issue 3 to me though.

---

_**Assistant**_

You're absolutely right about Issue 1 - the wrapping in an "output" field is how n8n formats the results and isn't something the agent can control. That's part of the workflow system's output formatting.

Regarding Issue 3, I think I misinterpreted the data structure. Looking more carefully:

The test data shows each shot is processed separately and contained in its own "output" object in the array:
```
[
  { "output": "[...scene-1_shot_2 data...]" },
  { "output": "[...scene-2_shot_3 data...]" },
  // etc.
]
```

This isn't actually a problem with the agent's output. Each shot is correctly being processed as a separate array as specified in our instructions:

```
For each B-roll shot in the Visual Narrative, create a separate JSON array containing prompt objects for all concepts of that shot.
```

What I initially interpreted as "multiple outputs" is actually the expected behavior - each shot is processed independently and returned as a separate JSON array, which is then wrapped by n8n's output structure. 

The agent is doing what we instructed - creating one JSON array per shot. The outer array wrapping is just n8n's way of organizing multiple response objects.

So I was incorrect about Issue 3 - the agent is behaving as intended regarding the output structure for multiple shots.

Would you like me to make changes to address the remaining issues (Issue 2 and 4) regarding motion language and animation terminology that's still appearing in the prompts?

---

_**User**_

yes fix issue 2 and 4.

---

_**Assistant**_

I'll update the instructions to better address issues with motion language and animation terminology still appearing in the prompts.

---

```diff
  **CRITICAL: MidJourney generates only static images, not videos or animations.**
  
- FORBIDDEN WORDS - DO NOT USE ANY OF THESE:
- - transitioning
- - transforming
- - moving
- - animating
- - zooming
- - panning
- - shifting
- - evolving
- - emerging
- - morphing
- - flowing
+ ABSOLUTELY FORBIDDEN TERMS (DO NOT USE THESE OR ANY VARIATIONS OF THEM):
+ 
+ ### Motion Terms:
+ - transitioning / transition
+ - transforming / transform
+ - moving / movement / motion
+ - animating / animated / animation
+ - zooming / zoom
+ - panning / pan
+ - shifting / shift
+ - evolving / evolution
+ - emerging / emerge
+ - morphing / morph
+ - flowing / flow
+ - dynamic
+ - kinetic
+ - progress / progression
+ - growth (when implying process)
+ - bursting
+ - exploding / explosion
  - time-lapse
- - sequence
- - progression
+ - sequence / sequential
+ 
+ ### Process Terms:
+ - becoming
+ - turning into
+ - changing into
+ - developing
+ - forming
+ - converting
+ - progress
+ - step
+ - phase
+ - stage
+ - before / after
+ 
+ ### Action Terms:
+ - triggering
+ - reacting
+ - releasing
+ - interacting
+ - responding
+ - falling (as in falling confetti)
+ - rising
+ - expanding
+ - growing
+ - appearing
+ - opening
+ - breaking
+ 
+ ### MidJourney Cannot Show:
+ - Multiple moments in time
+ - Before/after states
+ - Any form of movement
+ - Anything "in the process of" changing
+ - Objects "about to" do something
+ - Objects that "have just" done something
+ 
+ Instead, describe exactly what the FROZEN moment looks like, as if time has completely stopped. Imagine a single photograph that cannot imply motion in any way.
+ 
+ ## How to Describe Static Alternatives
+ 
+ INCORRECT ❌: "Confetti falling from the ceiling"
+ CORRECT ✓: "Confetti suspended in mid-air beneath the ceiling"
+ 
+ INCORRECT ❌: "A butterfly emerging from its cocoon"
+ CORRECT ✓: "A butterfly and partially opened cocoon captured in a single moment"
+ 
+ INCORRECT ❌: "Light transitioning from blue to amber"
+ CORRECT ✓: "Gradient of light from blue on one side to amber on the other side"
+ 
+ INCORRECT ❌: "Digital interface with animated icons"
+ CORRECT ✓: "Digital interface with vibrant, detailed icon designs"
+ 
+ INCORRECT ❌: "Journal transforming into a garden"
+ CORRECT ✓: "Surreal composite image of a journal with garden elements"
  
  Describe only what would be visible in a single static frame. Focus on describing a single moment in time as if frozen in a photograph.
  ### Enhanced Concept (Stylize 250-400)
  
- Holographic projections of AI applications floating in a stylized modern home environment, translucent blue interfaces hovering around everyday objects, a person's hands interacting with gesture controls, warm ambient lighting for home contrasted with cool blue emissions from interfaces, soft key light on hands, shot with medium-wide lens slightly below eye level, photorealistic rendering with crisp detail on interfaces --style raw --ar 16:9 --stylize 300
+ Holographic projections of AI applications displayed in a stylized modern home environment, translucent blue interfaces positioned around everyday objects, a person's hands posed near control elements, warm ambient lighting for home contrasted with cool blue emissions from interfaces, soft key light on hands, shot with medium-wide lens slightly below eye level, photorealistic rendering with crisp detail on interfaces --style raw --ar 16:9 --stylize 300
  
  ### Experimental Concept (Stylize 400-650)
  
- An abstract data ecosystem rendered as a luminescent digital garden, glowing plants and flowers made of data visualizations, cool blues and teals with warm amber tones, bioluminescent lighting from within the structures, intricate organic patterns forming data streams, hyperdetailed textures, shot with wide angle lens with shallow depth of field, cinematic lighting --ar 16:9 --stylize 500
+ An abstract data ecosystem depicted as a luminescent digital garden, glowing plants and flowers made of data visualizations, cool blues and teals alongside warm amber tones, bioluminescent lighting emanating from within the structures, intricate organic patterns of data streams, hyperdetailed textures, shot with wide angle lens with shallow depth of field, cinematic lighting --ar 16:9 --stylize 500
  
  ## Processing Steps
  - DO NOT add any text before or after the JSON array
  - DO NOT include periods at the end of prompts
- - DO NOT include words that imply motion or animation
- - DO NOT use ANY of the forbidden words listed above
+ - DO NOT use ANY words that imply motion, animation, or change
+ - DO NOT use ANY of the forbidden terms listed above (or variations of them)
+ - CHECK EACH PROMPT for accidental motion language before submitting
+ - Use only static, frozen-in-time descriptions 
  - Your response for each shot should begin with [ and end with ] with no other characters
  
```

---

I've made significant improvements to address issues with motion language and animation terminology:

1. **Expanded Forbidden Terms List**:
   - Organized into clear categories: Motion Terms, Process Terms, Action Terms
   - Added variations of each term (e.g., "transitioning/transition")
   - Added many new terms that imply motion or change
   - Added more subtle terms that were appearing in outputs like "bursting," "dynamic," and "interacting"

2. **Added "MidJourney Cannot Show" Section**:
   - Explicitly listed types of content MidJourney cannot render
   - Emphasized that multiple moments in time cannot be shown
   - Clarified that "process" descriptions are not possible

3. **Added "How to Describe Static Alternatives" Section**:
   - Provided direct examples of incorrect vs. correct phrasing
   - Used ❌ and ✓ symbols to clearly mark examples
   - Included examples that directly address problematic patterns in the current output
   - Showed how to rewrite common motion-implying phrases

4. **Fixed Example Prompts**:
   - Corrected the Enhanced and Experimental concept examples to remove subtle motion language
   - Replaced terms like "floating" with "displayed" and "hovering" with "positioned"
   - Changed "interacting with" to "posed near"
   - Fixed "forming" to "of" to avoid implying process

5. **Strengthened Final Reminders**:
   - Added explicit instruction to check each prompt for accidental motion language
   - Added reminder to use only static, frozen-in-time descriptions
   - Clarified that variations of forbidden terms are also banned
   - Expanded the warning about motion and animation to include "change"

These improvements provide much more comprehensive guidance on avoiding motion language, with concrete examples of how to rewrite problematic phrases into static descriptions. The expanded forbidden terms list should catch most of the problematic language that was appearing in the outputs.

---

_**User**_

Looking at your propsed changes I think your interpretation of motion is too literal. You can describe motion in an image even if it's a static shot. For example, a flowing river can be captired in a static shot. A human morphing into a werewolf could be caught in a static shot. There are many other examples. A do agree that camera moption should be prohibited but not motion or transformation of the subject for example. What do you think?

---

_**Assistant**_

You make an excellent point, and I agree that my interpretation of motion was too restrictive. You're absolutely right that static images can effectively capture or imply motion while still being single frames:

1. **Implied Motion in Static Images**: Photography and visual art have long techniques to suggest motion in still frames - like a flowing river, a person caught mid-stride, or hair blowing in the wind.

2. **Transformations in Single Frames**: Many artistic concepts show transformation or morphing (like a human partially transformed into a werewolf) in a single moment, which can be a powerful visual.

3. **Stylistic Visual Elements**: Terms like "dynamic" can refer to composition rather than literal movement.

I think we need a more nuanced approach that distinguishes between:
- Camera motion/techniques that can't be captured in a still (panning, zooming)
- Animation or sequence terms that suggest multiple frames (time-lapse, sequence)
- Terms that imply a process over time that can't be captured in one frame ("turning into")

Versus:
- Visual elements that imply motion but can be shown in a static image (flowing water, wind effects)
- Transformation states that can be captured at a specific moment (partial metamorphosis)
- Compositional terms that describe visual energy rather than actual movement

Would you like me to create a more nuanced version that preserves the ability to describe these dynamic visual elements while still prohibiting camera movements and terms that truly require multiple frames?

---

_**User**_

Yes and you may need to removed and replace some of the existing restrictive language also.

---

_**Assistant**_

I'll create a more nuanced approach to motion language that distinguishes between impossible camera motion versus implied motion that can be captured in a still image.

---

Cancelled

---



---



---

